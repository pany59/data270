{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "o3hAS_Fvj4f0"
   },
   "outputs": [],
   "source": [
    "# 可供参考 https://www.kaggle.com/code/surekharamireddy/spam-detection-with-99-accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "executionInfo": {
     "elapsed": 1258,
     "status": "error",
     "timestamp": 1681705973079,
     "user": {
      "displayName": "Johnny Qiu",
      "userId": "13742367285172598432"
     },
     "user_tz": 420
    },
    "id": "Gr6Ht94-ItoE",
    "outputId": "548f1433-406c-4d12-d2e9-f14d17c372c8"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 根目录\n",
    "root_dir = \"lingspam_public/bare\"\n",
    "\n",
    "# 创建DataFrame with 3 cols\n",
    "# df = pd.DataFrame(columns=[\"label\", \"subject\", \"main_body\"])\n",
    "df = []\n",
    "\n",
    "# 遍历根目录下的10个文件夹\n",
    "for i in range(1, 11):\n",
    "    folder = os.path.join(root_dir, \"part{}\".format(i))\n",
    "    file_list = os.listdir(folder)\n",
    "\n",
    "    # 遍历每个文件\n",
    "    for file_name in file_list:\n",
    "        # 重复文件名的去掉 df.drop_duplicates(subset=['file_name'], keep='first', inplace=True)\n",
    "\n",
    "        with open(os.path.join(folder, file_name), \"r\") as f:\n",
    "            file_content = f.readlines()\n",
    "\n",
    "            # 获取标签\n",
    "            if \"spm\" in file_name:\n",
    "                label = \"spam\"\n",
    "            else:\n",
    "                label = \"non-spam\"\n",
    "\n",
    "            # 获取主题行和正文\n",
    "            # 这里把Subject: 去掉了, 只留下subject本身\n",
    "            if file_name == \"Icon\": continue\n",
    "            if len(file_content) == 0:\n",
    "                print(folder, file_name)\n",
    "            else:\n",
    "                subject = file_content[0].replace(\"Subject: \", \"\").strip()\n",
    "            # 用strip()是为了防止存在换行符\\n\n",
    "            main_body = \"\".join([line.strip() for line in file_content[1:]])\n",
    "\n",
    "            # 将信息添加到DataFrame中\n",
    "            df.append(pd.DataFrame({\"label\": label, \"subject\": subject, \"main_body\": main_body}, index=[0]))\n",
    "\n",
    "# 将所有数据连接在一起\n",
    "df = pd.concat(df, ignore_index=True)\n",
    "\n",
    "# \"\"实际上不是空值, 他的值就是\"\"\n",
    "# 这里把所有\"\"替换成空值\n",
    "df[\"label\"].replace(\"\", np.nan, inplace=True)\n",
    "df[\"subject\"].replace(\"\", np.nan, inplace=True)\n",
    "df[\"main_body\"].replace(\"\", np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "QMHq10LSItoG",
    "outputId": "cba645ce-527a-44b5-a0d7-c2cd284e063f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>subject</th>\n",
       "      <th>main_body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>non-spam</td>\n",
       "      <td>conference announcement</td>\n",
       "      <td>* * * * * * * * * * * * * * * * * * * * * firs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spam</td>\n",
       "      <td>\" life without debt \"</td>\n",
       "      <td>pardon the intrusion . no offence is meant . i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>do want the best and economical hunting vacati...</td>\n",
       "      <td>if you want the best hunting and camping vacat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>non-spam</td>\n",
       "      <td>query : uninflected tags</td>\n",
       "      <td>does anybody know of recent work on uninflecte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>non-spam</td>\n",
       "      <td>no accent allowed !</td>\n",
       "      <td>has anybody else seen a weird piece in a newsp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2888</th>\n",
       "      <td>non-spam</td>\n",
       "      <td>sla conference paris 1999</td>\n",
       "      <td>call for papers xi th international conference...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2889</th>\n",
       "      <td>non-spam</td>\n",
       "      <td>conference announcement</td>\n",
       "      <td>southern illinois university edwardsville and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2890</th>\n",
       "      <td>non-spam</td>\n",
       "      <td>semantics</td>\n",
       "      <td>we would like to bring to your attention to tw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2891</th>\n",
       "      <td>non-spam</td>\n",
       "      <td>honored by two keynote speakers</td>\n",
       "      <td>international conference on natural language p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2892</th>\n",
       "      <td>non-spam</td>\n",
       "      <td>typology</td>\n",
       "      <td>we would like to bring to your attention recen...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2893 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         label                                            subject  \\\n",
       "0     non-spam                            conference announcement   \n",
       "1         spam                              \" life without debt \"   \n",
       "2         spam  do want the best and economical hunting vacati...   \n",
       "3     non-spam                           query : uninflected tags   \n",
       "4     non-spam                                no accent allowed !   \n",
       "...        ...                                                ...   \n",
       "2888  non-spam                          sla conference paris 1999   \n",
       "2889  non-spam                            conference announcement   \n",
       "2890  non-spam                                          semantics   \n",
       "2891  non-spam                    honored by two keynote speakers   \n",
       "2892  non-spam                                           typology   \n",
       "\n",
       "                                              main_body  \n",
       "0     * * * * * * * * * * * * * * * * * * * * * firs...  \n",
       "1     pardon the intrusion . no offence is meant . i...  \n",
       "2     if you want the best hunting and camping vacat...  \n",
       "3     does anybody know of recent work on uninflecte...  \n",
       "4     has anybody else seen a weird piece in a newsp...  \n",
       "...                                                 ...  \n",
       "2888  call for papers xi th international conference...  \n",
       "2889  southern illinois university edwardsville and ...  \n",
       "2890  we would like to bring to your attention to tw...  \n",
       "2891  international conference on natural language p...  \n",
       "2892  we would like to bring to your attention recen...  \n",
       "\n",
       "[2893 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "7MgaaCRrj4f5"
   },
   "outputs": [],
   "source": [
    "# df.to_csv(\"dataframe.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QiIaXFhGj4f6"
   },
   "source": [
    "# assignment #7 参考kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "y-Logy_cj4f7",
    "outputId": "abe32cd0-0fc8-4246-ae3d-b2b3a714876b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label         0\n",
       "subject      62\n",
       "main_body     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check null values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Gd9hXKurj4f7",
    "outputId": "118db9a4-8ee1-4b1f-a639-68b9afcf4afd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>subject</th>\n",
       "      <th>main_body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>non-spam</td>\n",
       "      <td>conference announcement</td>\n",
       "      <td>* * * * * * * * * * * * * * * * * * * * * firs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spam</td>\n",
       "      <td>\" life without debt \"</td>\n",
       "      <td>pardon the intrusion . no offence is meant . i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>do want the best and economical hunting vacati...</td>\n",
       "      <td>if you want the best hunting and camping vacat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>non-spam</td>\n",
       "      <td>query : uninflected tags</td>\n",
       "      <td>does anybody know of recent work on uninflecte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>non-spam</td>\n",
       "      <td>no accent allowed !</td>\n",
       "      <td>has anybody else seen a weird piece in a newsp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2888</th>\n",
       "      <td>non-spam</td>\n",
       "      <td>sla conference paris 1999</td>\n",
       "      <td>call for papers xi th international conference...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2889</th>\n",
       "      <td>non-spam</td>\n",
       "      <td>conference announcement</td>\n",
       "      <td>southern illinois university edwardsville and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2890</th>\n",
       "      <td>non-spam</td>\n",
       "      <td>semantics</td>\n",
       "      <td>we would like to bring to your attention to tw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2891</th>\n",
       "      <td>non-spam</td>\n",
       "      <td>honored by two keynote speakers</td>\n",
       "      <td>international conference on natural language p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2892</th>\n",
       "      <td>non-spam</td>\n",
       "      <td>typology</td>\n",
       "      <td>we would like to bring to your attention recen...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2893 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         label                                            subject  \\\n",
       "0     non-spam                            conference announcement   \n",
       "1         spam                              \" life without debt \"   \n",
       "2         spam  do want the best and economical hunting vacati...   \n",
       "3     non-spam                           query : uninflected tags   \n",
       "4     non-spam                                no accent allowed !   \n",
       "...        ...                                                ...   \n",
       "2888  non-spam                          sla conference paris 1999   \n",
       "2889  non-spam                            conference announcement   \n",
       "2890  non-spam                                          semantics   \n",
       "2891  non-spam                    honored by two keynote speakers   \n",
       "2892  non-spam                                           typology   \n",
       "\n",
       "                                              main_body  \n",
       "0     * * * * * * * * * * * * * * * * * * * * * firs...  \n",
       "1     pardon the intrusion . no offence is meant . i...  \n",
       "2     if you want the best hunting and camping vacat...  \n",
       "3     does anybody know of recent work on uninflecte...  \n",
       "4     has anybody else seen a weird piece in a newsp...  \n",
       "...                                                 ...  \n",
       "2888  call for papers xi th international conference...  \n",
       "2889  southern illinois university edwardsville and ...  \n",
       "2890  we would like to bring to your attention to tw...  \n",
       "2891  international conference on natural language p...  \n",
       "2892  we would like to bring to your attention recen...  \n",
       "\n",
       "[2893 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Data Cleaning: Handling of Incomplete & Missing Data\n",
    "\n",
    "miss label - drop\n",
    "miss subject - keep\n",
    "miss main body - drop\n",
    "'''\n",
    "# 如果主题行缺失，则用 Missing 替代\n",
    "# df[\"subject\"] = df[\"subject\"].fillna(\"missing\")\n",
    "df[\"subject\"].fillna(\"missing\", inplace=True)\n",
    "\n",
    "# 直接删掉\n",
    "df.dropna(subset=[\"label\"], inplace=True)\n",
    "df.dropna(subset=[\"main_body\"], inplace=True)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "wRz__hVWelFA",
    "outputId": "3c73bc96-fd3a-4987-b25b-f035776de56c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/73/c0d3xlnj7zxgmh873jh1p15c0000gn/T/ipykernel_39926/2136244614.py:33: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['subject']=df['subject'].str.replace(r'\\d+(\\.\\d+)?', 'numbers')\n",
      "/var/folders/73/c0d3xlnj7zxgmh873jh1p15c0000gn/T/ipykernel_39926/2136244614.py:34: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['main_body']=df['main_body'].str.replace(r'\\d+(\\.\\d+)?', 'numbers')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>subject</th>\n",
       "      <th>main_body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>non-spam</td>\n",
       "      <td>conference announcement</td>\n",
       "      <td>first announcement       ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spam</td>\n",
       "      <td>life without debt</td>\n",
       "      <td>pardon the intrusion  no offence is meant  if ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>do want the best and economical hunting vacati...</td>\n",
       "      <td>if you want the best hunting and camping vacat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>non-spam</td>\n",
       "      <td>query  uninflected tags</td>\n",
       "      <td>does anybody know of recent work on uninflecte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>non-spam</td>\n",
       "      <td>no accent allowed</td>\n",
       "      <td>has anybody else seen a weird piece in a newsp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2886</th>\n",
       "      <td>non-spam</td>\n",
       "      <td>program  info  workshop on comparative slavic ...</td>\n",
       "      <td>workshop on comparative slavic morphosyntax pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2887</th>\n",
       "      <td>non-spam</td>\n",
       "      <td>tsdnumbers   numbersrd call for papers</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2888</th>\n",
       "      <td>non-spam</td>\n",
       "      <td>sla conference paris numbers</td>\n",
       "      <td>call for papers xi th international conference...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2891</th>\n",
       "      <td>non-spam</td>\n",
       "      <td>honored by two keynote speakers</td>\n",
       "      <td>international conference on natural language p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2892</th>\n",
       "      <td>non-spam</td>\n",
       "      <td>typology</td>\n",
       "      <td>we would like to bring to your attention recen...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2597 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         label                                            subject  \\\n",
       "0     non-spam                            conference announcement   \n",
       "1         spam                                 life without debt    \n",
       "2         spam  do want the best and economical hunting vacati...   \n",
       "3     non-spam                            query  uninflected tags   \n",
       "4     non-spam                                 no accent allowed    \n",
       "...        ...                                                ...   \n",
       "2886  non-spam  program  info  workshop on comparative slavic ...   \n",
       "2887  non-spam             tsdnumbers   numbersrd call for papers   \n",
       "2888  non-spam                       sla conference paris numbers   \n",
       "2891  non-spam                    honored by two keynote speakers   \n",
       "2892  non-spam                                           typology   \n",
       "\n",
       "                                              main_body  \n",
       "0                          first announcement       ...  \n",
       "1     pardon the intrusion  no offence is meant  if ...  \n",
       "2     if you want the best hunting and camping vacat...  \n",
       "3     does anybody know of recent work on uninflecte...  \n",
       "4     has anybody else seen a weird piece in a newsp...  \n",
       "...                                                 ...  \n",
       "2886  workshop on comparative slavic morphosyntax pr...  \n",
       "2887                                                ...  \n",
       "2888  call for papers xi th international conference...  \n",
       "2891  international conference on natural language p...  \n",
       "2892  we would like to bring to your attention recen...  \n",
       "\n",
       "[2597 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Data Cleaning: Handling of Noisy Data\n",
    "\n",
    "noisy data -> meaningless data: all punctuations -> drop\n",
    "noisy data -> redundant data: repetitive data -> drop\n",
    "# REPLACING EMAIL IDs BY 'MAILID'\n",
    "# REPLACING URLs  BY 'Links'\n",
    "# REPLACING CURRENCY SIGNS BY 'MONEY'\n",
    "# REPLACINg NUMBERS by 'numbers'\n",
    "'''\n",
    "\n",
    "# drop all punctuations\n",
    "df['subject'] = df['subject'].str.replace(r'[^\\w\\s]', '', regex=True)\n",
    "df['main_body'] = df['main_body'].str.replace(r'[^\\w\\s]', '', regex=True)\n",
    "\n",
    "# drop repetitive data\n",
    "df.drop_duplicates(subset=[\"subject\"], inplace=True) # 可以删掉\n",
    "df.drop_duplicates(subset=[\"main_body\"], inplace=True)\n",
    "\n",
    "# replace email by 'MailID'\n",
    "df['subject']=df['subject'].str.replace(r'^.+@[^\\.].*\\.[a-z]{2,}$','MailID', regex=True) # 可以删掉\n",
    "df['main_body']=df['main_body'].str.replace(r'^.+@[^\\.].*\\.[a-z]{2,}$','MailID', regex=True)\n",
    "\n",
    "# replace links by 'Links'\n",
    "df['subject']=df['subject'].str.replace(r'^http\\://[a-zA-Z0-9\\-\\.]+\\.[a-zA-Z]{2,3}(/\\S*)?$','Links', regex=True) # 可以删掉\n",
    "df['main_body']=df['main_body'].str.replace(r'^http\\://[a-zA-Z0-9\\-\\.]+\\.[a-zA-Z]{2,3}(/\\S*)?$','Links', regex=True)\n",
    "\n",
    "# replace currency by 'money'\n",
    "df['subject']=df['subject'].str.replace(r'£|\\$', 'money', regex=True)\n",
    "df['main_body']=df['main_body'].str.replace(r'£|\\$', 'money', regex=True)\n",
    "\n",
    "# replace numbers by 'numbers'\n",
    "df['subject']=df['subject'].str.replace(r'\\d+(\\.\\d+)?', 'numbers')\n",
    "df['main_body']=df['main_body'].str.replace(r'\\d+(\\.\\d+)?', 'numbers')\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "IPHepPBAelFB",
    "outputId": "c349f955-929b-4a01-b8c5-49813637b7a4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>subject</th>\n",
       "      <th>main_body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>non-spam</td>\n",
       "      <td>conference announcement</td>\n",
       "      <td>first announcement groningen assembly on lang...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spam</td>\n",
       "      <td>life without debt</td>\n",
       "      <td>pardon the intrusion no offence is meant if yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>do want the best and economical hunting vacati...</td>\n",
       "      <td>if you want the best hunting and camping vacat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>non-spam</td>\n",
       "      <td>query uninflected tags</td>\n",
       "      <td>does anybody know of recent work on uninflecte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>non-spam</td>\n",
       "      <td>no accent allowed</td>\n",
       "      <td>has anybody else seen a weird piece in a newsp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2886</th>\n",
       "      <td>non-spam</td>\n",
       "      <td>program info workshop on comparative slavic mo...</td>\n",
       "      <td>workshop on comparative slavic morphosyntax pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2887</th>\n",
       "      <td>non-spam</td>\n",
       "      <td>tsdnumbers numbersrd call for papers</td>\n",
       "      <td>please pay attention deadline for submissions...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2888</th>\n",
       "      <td>non-spam</td>\n",
       "      <td>sla conference paris numbers</td>\n",
       "      <td>call for papers xi th international conference...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2891</th>\n",
       "      <td>non-spam</td>\n",
       "      <td>honored by two keynote speakers</td>\n",
       "      <td>international conference on natural language p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2892</th>\n",
       "      <td>non-spam</td>\n",
       "      <td>typology</td>\n",
       "      <td>we would like to bring to your attention recen...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2597 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         label                                            subject  \\\n",
       "0     non-spam                            conference announcement   \n",
       "1         spam                                 life without debt    \n",
       "2         spam  do want the best and economical hunting vacati...   \n",
       "3     non-spam                             query uninflected tags   \n",
       "4     non-spam                                 no accent allowed    \n",
       "...        ...                                                ...   \n",
       "2886  non-spam  program info workshop on comparative slavic mo...   \n",
       "2887  non-spam               tsdnumbers numbersrd call for papers   \n",
       "2888  non-spam                       sla conference paris numbers   \n",
       "2891  non-spam                    honored by two keynote speakers   \n",
       "2892  non-spam                                           typology   \n",
       "\n",
       "                                              main_body  \n",
       "0      first announcement groningen assembly on lang...  \n",
       "1     pardon the intrusion no offence is meant if yo...  \n",
       "2     if you want the best hunting and camping vacat...  \n",
       "3     does anybody know of recent work on uninflecte...  \n",
       "4     has anybody else seen a weird piece in a newsp...  \n",
       "...                                                 ...  \n",
       "2886  workshop on comparative slavic morphosyntax pr...  \n",
       "2887   please pay attention deadline for submissions...  \n",
       "2888  call for papers xi th international conference...  \n",
       "2891  international conference on natural language p...  \n",
       "2892  we would like to bring to your attention recen...  \n",
       "\n",
       "[2597 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Data Cleaning: Handling of Inconsistent Data\n",
    "\n",
    "lowercase / uppercase -> all lowercase\n",
    "# REPLACING NEXT LINES BY 'WHITE SPACE'\n",
    "# REPLACING LARGE WHITE SPACE BY SINGLE WHITE SPACE\n",
    "# REPLACING LEADING AND TRAILING WHITE SPACE BY SINGLE WHITE SPACE\n",
    "# REPLACING SPECIAL CHARACTERS  BY WHITE SPACE\n",
    "'''\n",
    "\n",
    "# convert to lowercase\n",
    "df['subject']=df['subject'].str.lower()\n",
    "df['main_body']=df['main_body'].str.lower()\n",
    "\n",
    "# replace special characters by white space\n",
    "df['subject']=df['subject'].str.replace(r\"[^a-zA-Z0-9]+\", \" \", regex=True)\n",
    "df['main_body']=df['main_body'].str.replace(r\"[^a-zA-Z0-9]+\", \" \", regex=True)\n",
    "\n",
    "# replace leading and trailing white space by single white space\n",
    "df['subject']=df['subject'].str.replace(r'^\\s+|\\s+?$', ' ', regex=True)\n",
    "df['main_body']=df['main_body'].str.replace(r'^\\s+|\\s+?$', ' ', regex=True)\n",
    "\n",
    "# replace next line by white space\n",
    "df['subject']=df['subject'].str.replace(r'\\n',\" \", regex=True)\n",
    "df['main_body']=df['main_body'].str.replace(r'\\n',\" \", regex=True)\n",
    "\n",
    "# 这个要放最后\n",
    "# replace large white space by single white space\n",
    "df['subject']=df['subject'].str.replace(r'\\s+', ' ', regex=True)\n",
    "df['main_body']=df['main_body'].str.replace(r'\\s+', ' ', regex=True)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "TKvHQ66mj4f9",
    "outputId": "6f86cc00-9768-4ea0-fc10-3953db85caa2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>subject</th>\n",
       "      <th>length</th>\n",
       "      <th>main_body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>non-spam</td>\n",
       "      <td>conference announcement</td>\n",
       "      <td>1278</td>\n",
       "      <td>first announcement groningen assembly on lang...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spam</td>\n",
       "      <td>life without debt</td>\n",
       "      <td>1658</td>\n",
       "      <td>pardon the intrusion no offence is meant if yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>do want the best and economical hunting vacati...</td>\n",
       "      <td>592</td>\n",
       "      <td>if you want the best hunting and camping vacat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>non-spam</td>\n",
       "      <td>query uninflected tags</td>\n",
       "      <td>266</td>\n",
       "      <td>does anybody know of recent work on uninflecte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>non-spam</td>\n",
       "      <td>no accent allowed</td>\n",
       "      <td>1371</td>\n",
       "      <td>has anybody else seen a weird piece in a newsp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2886</th>\n",
       "      <td>non-spam</td>\n",
       "      <td>program info workshop on comparative slavic mo...</td>\n",
       "      <td>11168</td>\n",
       "      <td>workshop on comparative slavic morphosyntax pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2887</th>\n",
       "      <td>non-spam</td>\n",
       "      <td>tsdnumbers numbersrd call for papers</td>\n",
       "      <td>6044</td>\n",
       "      <td>please pay attention deadline for submissions...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2888</th>\n",
       "      <td>non-spam</td>\n",
       "      <td>sla conference paris numbers</td>\n",
       "      <td>2034</td>\n",
       "      <td>call for papers xi th international conference...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2891</th>\n",
       "      <td>non-spam</td>\n",
       "      <td>honored by two keynote speakers</td>\n",
       "      <td>1879</td>\n",
       "      <td>international conference on natural language p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2892</th>\n",
       "      <td>non-spam</td>\n",
       "      <td>typology</td>\n",
       "      <td>5248</td>\n",
       "      <td>we would like to bring to your attention recen...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2596 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         label                                            subject  length  \\\n",
       "0     non-spam                            conference announcement    1278   \n",
       "1         spam                                 life without debt     1658   \n",
       "2         spam  do want the best and economical hunting vacati...     592   \n",
       "3     non-spam                             query uninflected tags     266   \n",
       "4     non-spam                                 no accent allowed     1371   \n",
       "...        ...                                                ...     ...   \n",
       "2886  non-spam  program info workshop on comparative slavic mo...   11168   \n",
       "2887  non-spam               tsdnumbers numbersrd call for papers    6044   \n",
       "2888  non-spam                       sla conference paris numbers    2034   \n",
       "2891  non-spam                    honored by two keynote speakers    1879   \n",
       "2892  non-spam                                           typology    5248   \n",
       "\n",
       "                                              main_body  \n",
       "0      first announcement groningen assembly on lang...  \n",
       "1     pardon the intrusion no offence is meant if yo...  \n",
       "2     if you want the best hunting and camping vacat...  \n",
       "3     does anybody know of recent work on uninflecte...  \n",
       "4     has anybody else seen a weird piece in a newsp...  \n",
       "...                                                 ...  \n",
       "2886  workshop on comparative slavic morphosyntax pr...  \n",
       "2887   please pay attention deadline for submissions...  \n",
       "2888  call for papers xi th international conference...  \n",
       "2891  international conference on natural language p...  \n",
       "2892  we would like to bring to your attention recen...  \n",
       "\n",
       "[2596 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 在完成后续的操作以后可能原本不是空的main body会变成空\n",
    "# 所以可能需要再次处理\n",
    "df[\"subject\"].replace(\" \", np.nan, inplace=True)\n",
    "df[\"main_body\"].replace(\" \", np.nan, inplace=True)\n",
    "\n",
    "df[\"subject\"].fillna(\"missing\", inplace=True)\n",
    "df.dropna(subset=[\"main_body\"], inplace=True)\n",
    "\n",
    "df.insert(len(df.columns)-1, 'length', df['main_body'].apply(len))\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "aMQY3sQlj4f-"
   },
   "outputs": [],
   "source": [
    "# df.to_csv(\"cleaned_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dPyKfsZfkiGF"
   },
   "source": [
    "## Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "5yuJ-Ay9kP8T"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/lucyy/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "TTWbRe4uelFD"
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# removing stopwords\n",
    "stop = stopwords.words('english')\n",
    "df['subject'] = df['subject'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
    "df['main_body'] = df['main_body'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
    "\n",
    "# Apply lemmatization\n",
    "lemm = WordNetLemmatizer()\n",
    "df['subject'] = df['subject'].apply(lambda x: ' '.join([lemm.lemmatize(word, pos=\"v\") for word in x.split()]))\n",
    "df['main_body'] = df['main_body'].apply(lambda x: ' '.join([lemm.lemmatize(word, pos=\"v\") for word in x.split()]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"label\"].replace(\"non-spam\", 0, inplace=True)\n",
    "df[\"label\"].replace(\"spam\", 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "UiCSpfPrlWLH",
    "outputId": "0fe333ac-0abd-4a18-f881-df830758f3d7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>subject</th>\n",
       "      <th>length</th>\n",
       "      <th>main_body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>conference announcement</td>\n",
       "      <td>1064</td>\n",
       "      <td>first announcement groningen assembly language...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>life without debt</td>\n",
       "      <td>1185</td>\n",
       "      <td>pardon intrusion offence mean interest simply ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>want best economical hunt vacation life</td>\n",
       "      <td>445</td>\n",
       "      <td>want best hunt camp vacation life come felton ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>query uninflected tag</td>\n",
       "      <td>190</td>\n",
       "      <td>anybody know recent work uninflected tag like ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>accent allow</td>\n",
       "      <td>1004</td>\n",
       "      <td>anybody else see weird piece newspaper read su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2886</th>\n",
       "      <td>0</td>\n",
       "      <td>program info workshop comparative slavic morph...</td>\n",
       "      <td>8525</td>\n",
       "      <td>workshop comparative slavic morphosyntax progr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2887</th>\n",
       "      <td>0</td>\n",
       "      <td>tsdnumbers numbersrd call paper</td>\n",
       "      <td>4713</td>\n",
       "      <td>please pay attention deadline submissions may ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2888</th>\n",
       "      <td>0</td>\n",
       "      <td>sla conference paris number</td>\n",
       "      <td>1720</td>\n",
       "      <td>call paper xi th international conference acqu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2891</th>\n",
       "      <td>0</td>\n",
       "      <td>honor two keynote speakers</td>\n",
       "      <td>1677</td>\n",
       "      <td>international conference natural language proc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2892</th>\n",
       "      <td>0</td>\n",
       "      <td>typology</td>\n",
       "      <td>4165</td>\n",
       "      <td>would like bring attention recent publications...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2596 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                            subject  length  \\\n",
       "0         0                            conference announcement    1064   \n",
       "1         1                                  life without debt    1185   \n",
       "2         1            want best economical hunt vacation life     445   \n",
       "3         0                              query uninflected tag     190   \n",
       "4         0                                       accent allow    1004   \n",
       "...     ...                                                ...     ...   \n",
       "2886      0  program info workshop comparative slavic morph...    8525   \n",
       "2887      0                    tsdnumbers numbersrd call paper    4713   \n",
       "2888      0                        sla conference paris number    1720   \n",
       "2891      0                         honor two keynote speakers    1677   \n",
       "2892      0                                           typology    4165   \n",
       "\n",
       "                                              main_body  \n",
       "0     first announcement groningen assembly language...  \n",
       "1     pardon intrusion offence mean interest simply ...  \n",
       "2     want best hunt camp vacation life come felton ...  \n",
       "3     anybody know recent work uninflected tag like ...  \n",
       "4     anybody else see weird piece newspaper read su...  \n",
       "...                                                 ...  \n",
       "2886  workshop comparative slavic morphosyntax progr...  \n",
       "2887  please pay attention deadline submissions may ...  \n",
       "2888  call paper xi th international conference acqu...  \n",
       "2891  international conference natural language proc...  \n",
       "2892  would like bring attention recent publications...  \n",
       "\n",
       "[2596 rows x 4 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To see the change in text length after removing stop words\n",
    "df['length']=df['main_body'].apply(len)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "I-_K1rsselFE"
   },
   "outputs": [],
   "source": [
    "# 更正由于drop stop words导致的空值\n",
    "df['subject']=df['subject'].str.replace(r'\\s+', ' ', regex=True)\n",
    "df['main_body']=df['main_body'].str.replace(r'\\s+', ' ', regex=True)\n",
    "\n",
    "df[\"subject\"].replace(\" \", np.nan, inplace=True)\n",
    "df[\"main_body\"].replace(\" \", np.nan, inplace=True)\n",
    "\n",
    "df[\"subject\"].fillna(\"missing\", inplace=True)\n",
    "df.dropna(subset=[\"main_body\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "SAWeOR-UelFE"
   },
   "outputs": [],
   "source": [
    "# df.to_csv(\"removedstop_cleaned_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "kekL7p5Flc7A",
    "outputId": "bd441dfd-e999-440c-c9df-b6c42d239afc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aaa</th>\n",
       "      <th>aaai</th>\n",
       "      <th>aaainumbers</th>\n",
       "      <th>aaal</th>\n",
       "      <th>aaanumbers</th>\n",
       "      <th>aaarghh</th>\n",
       "      <th>aaas</th>\n",
       "      <th>aabb</th>\n",
       "      <th>aabyhoej</th>\n",
       "      <th>...</th>\n",
       "      <th>zwischen</th>\n",
       "      <th>zwitserlood</th>\n",
       "      <th>zxgahnumbersqabjh</th>\n",
       "      <th>zybatov</th>\n",
       "      <th>zybatow</th>\n",
       "      <th>zygmunt</th>\n",
       "      <th>zyokyoozyu</th>\n",
       "      <th>zytkow</th>\n",
       "      <th>zzlsa</th>\n",
       "      <th>zznumbers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2591</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2592</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2593</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2594</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2595</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2596 rows × 51294 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       aa  aaa  aaai  aaainumbers  aaal  aaanumbers  aaarghh  aaas  aabb  \\\n",
       "0     0.0  0.0   0.0          0.0   0.0         0.0      0.0   0.0   0.0   \n",
       "1     0.0  0.0   0.0          0.0   0.0         0.0      0.0   0.0   0.0   \n",
       "2     0.0  0.0   0.0          0.0   0.0         0.0      0.0   0.0   0.0   \n",
       "3     0.0  0.0   0.0          0.0   0.0         0.0      0.0   0.0   0.0   \n",
       "4     0.0  0.0   0.0          0.0   0.0         0.0      0.0   0.0   0.0   \n",
       "...   ...  ...   ...          ...   ...         ...      ...   ...   ...   \n",
       "2591  0.0  0.0   0.0          0.0   0.0         0.0      0.0   0.0   0.0   \n",
       "2592  0.0  0.0   0.0          0.0   0.0         0.0      0.0   0.0   0.0   \n",
       "2593  0.0  0.0   0.0          0.0   0.0         0.0      0.0   0.0   0.0   \n",
       "2594  0.0  0.0   0.0          0.0   0.0         0.0      0.0   0.0   0.0   \n",
       "2595  0.0  0.0   0.0          0.0   0.0         0.0      0.0   0.0   0.0   \n",
       "\n",
       "      aabyhoej  ...  zwischen  zwitserlood  zxgahnumbersqabjh  zybatov  \\\n",
       "0          0.0  ...       0.0          0.0                0.0      0.0   \n",
       "1          0.0  ...       0.0          0.0                0.0      0.0   \n",
       "2          0.0  ...       0.0          0.0                0.0      0.0   \n",
       "3          0.0  ...       0.0          0.0                0.0      0.0   \n",
       "4          0.0  ...       0.0          0.0                0.0      0.0   \n",
       "...        ...  ...       ...          ...                ...      ...   \n",
       "2591       0.0  ...       0.0          0.0                0.0      0.0   \n",
       "2592       0.0  ...       0.0          0.0                0.0      0.0   \n",
       "2593       0.0  ...       0.0          0.0                0.0      0.0   \n",
       "2594       0.0  ...       0.0          0.0                0.0      0.0   \n",
       "2595       0.0  ...       0.0          0.0                0.0      0.0   \n",
       "\n",
       "      zybatow  zygmunt  zyokyoozyu  zytkow  zzlsa  zznumbers  \n",
       "0         0.0      0.0         0.0     0.0    0.0        0.0  \n",
       "1         0.0      0.0         0.0     0.0    0.0        0.0  \n",
       "2         0.0      0.0         0.0     0.0    0.0        0.0  \n",
       "3         0.0      0.0         0.0     0.0    0.0        0.0  \n",
       "4         0.0      0.0         0.0     0.0    0.0        0.0  \n",
       "...       ...      ...         ...     ...    ...        ...  \n",
       "2591      0.0      0.0         0.0     0.0    0.0        0.0  \n",
       "2592      0.0      0.0         0.0     0.0    0.0        0.0  \n",
       "2593      0.0      0.0         0.0     0.0    0.0        0.0  \n",
       "2594      0.0      0.0         0.0     0.0    0.0        0.0  \n",
       "2595      0.0      0.0         0.0     0.0    0.0        0.0  \n",
       "\n",
       "[2596 rows x 51294 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectors = vectorizer.fit_transform(df['main_body'])\n",
    "df1 = pd.DataFrame(vectors.toarray(), columns=vectorizer.get_feature_names())\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "ywwUAB9uliXg",
    "outputId": "0aa6b66c-4b5b-4731-f902-3cd95b34452d"
   },
   "outputs": [],
   "source": [
    "# from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# # n_components must be between 1 and min(vectors.shape)\n",
    "# svd = TruncatedSVD(n_components=1750)\n",
    "# svd.fit(vectors)\n",
    "# print(svd.explained_variance_ratio_.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "D4bbVs7qlllW",
    "outputId": "5c2474e7-eb55-4fe8-8c08-0506cd28ad11"
   },
   "outputs": [],
   "source": [
    "# transformed_vectors = svd.transform(vectors)\n",
    "# print(transformed_vectors)\n",
    "# print(\"dimension =\", transformed_vectors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 降维后的\n",
    "# df1 = pd.DataFrame(transformed_vectors)\n",
    "# df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "P71sJvnwPxNl"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# https://mccormickml.com/2019/05/14/BERT-word-embeddings-tutorial/\\nfrom transformers import BertModel,BertTokenizer\\nimport torch\\n\\nbert_model = BertModel.from_pretrained(\\'bert-base-uncased\\', output_hidden_states = True)\\nbert_tokenizer = BertTokenizer.from_pretrained(\\'bert-base-uncased\\')\\n\\ndef get_bert_embeddings(text, model, tokenizer):\\n\\n    marked_text = \"[CLS] \" + text + \" [SEP]\"\\n    tokenized_text = tokenizer.tokenize(marked_text)\\n    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\\n    segments_ids = [1]*len(indexed_tokens)\\n\\n    # convert inputs to tensors\\n    tokens_tensor = torch.tensor([indexed_tokens])\\n    segments_tensor = torch.tensor([segments_ids])\\n\\n    with torch.no_grad():\\n        # obtain hidden states\\n        outputs = model(tokens_tensor, segments_tensor)\\n        hidden_states = outputs[2]\\n\\n    # `token_vecs` is a tensor with shape [22 x 768]\\n    token_vecs = hidden_states[-2][0]\\n\\n    # Calculate the average of all 22 token vectors.\\n    sentence_embedding = torch.mean(token_vecs, dim=0)\\n\\n    return sentence_embedding'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# https://mccormickml.com/2019/05/14/BERT-word-embeddings-tutorial/\n",
    "from transformers import BertModel,BertTokenizer\n",
    "import torch\n",
    "\n",
    "bert_model = BertModel.from_pretrained('bert-base-uncased', output_hidden_states = True)\n",
    "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def get_bert_embeddings(text, model, tokenizer):\n",
    "\n",
    "    marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
    "    tokenized_text = tokenizer.tokenize(marked_text)\n",
    "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "    segments_ids = [1]*len(indexed_tokens)\n",
    "\n",
    "    # convert inputs to tensors\n",
    "    tokens_tensor = torch.tensor([indexed_tokens])\n",
    "    segments_tensor = torch.tensor([segments_ids])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # obtain hidden states\n",
    "        outputs = model(tokens_tensor, segments_tensor)\n",
    "        hidden_states = outputs[2]\n",
    "\n",
    "    # `token_vecs` is a tensor with shape [22 x 768]\n",
    "    token_vecs = hidden_states[-2][0]\n",
    "\n",
    "    # Calculate the average of all 22 token vectors.\n",
    "    sentence_embedding = torch.mean(token_vecs, dim=0)\n",
    "\n",
    "    return sentence_embedding'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "Ci_sCozO4xuu"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef get_bert_word_vectors(text, model, tokenizer):\\n\\n    marked_text = \"[CLS] \" + text + \" [SEP]\"\\n    tokenized_text = tokenizer.tokenize(marked_text)\\n    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\\n    segments_ids = [1]*len(indexed_tokens)\\n\\n    # convert inputs to tensors\\n    tokens_tensor = torch.tensor([indexed_tokens])\\n    segments_tensor = torch.tensor([segments_ids])\\n    \\n    with torch.no_grad():\\n        # obtain hidden states\\n        outputs = model(tokens_tensor, segments_tensor)\\n        hidden_states = outputs[2]\\n\\n    # concatenate the tensors for all layers\\n    # use \"stack\" to create new dimension in tensor\\n    token_embeddings = torch.stack(hidden_states, dim=0)\\n\\n    # # remove dimension 1, the \"batches\"\\n    token_embeddings = torch.squeeze(token_embeddings, dim=1)\\n\\n    # # swap dimensions 0 and 1 so we can loop over tokens\\n    token_embeddings = token_embeddings.permute(1,0,2)\\n\\n    # # intialized list to store embeddings\\n    token_vecs_sum = []\\n\\n    # # \"token_embeddings\" is a [Y x 12 x 768] tensor\\n    # # where Y is the number of tokens in the sentence\\n\\n    # # loop over tokens in sentence\\n    for token in token_embeddings:\\n\\n        # \"token\" is a [12 x 768] tensor\\n\\n        # sum the vectors from the last four layers\\n        sum_vec = torch.sum(token[-4:], dim=0)\\n        token_vecs_sum.append(sum_vec)\\n\\n    return token_vecs_sum\\n'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 如果需要做word vectors的话\n",
    "\"\"\"\n",
    "def get_bert_word_vectors(text, model, tokenizer):\n",
    "\n",
    "    marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
    "    tokenized_text = tokenizer.tokenize(marked_text)\n",
    "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "    segments_ids = [1]*len(indexed_tokens)\n",
    "\n",
    "    # convert inputs to tensors\n",
    "    tokens_tensor = torch.tensor([indexed_tokens])\n",
    "    segments_tensor = torch.tensor([segments_ids])\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # obtain hidden states\n",
    "        outputs = model(tokens_tensor, segments_tensor)\n",
    "        hidden_states = outputs[2]\n",
    "\n",
    "    # concatenate the tensors for all layers\n",
    "    # use \"stack\" to create new dimension in tensor\n",
    "    token_embeddings = torch.stack(hidden_states, dim=0)\n",
    "\n",
    "    # # remove dimension 1, the \"batches\"\n",
    "    token_embeddings = torch.squeeze(token_embeddings, dim=1)\n",
    "\n",
    "    # # swap dimensions 0 and 1 so we can loop over tokens\n",
    "    token_embeddings = token_embeddings.permute(1,0,2)\n",
    "\n",
    "    # # intialized list to store embeddings\n",
    "    token_vecs_sum = []\n",
    "\n",
    "    # # \"token_embeddings\" is a [Y x 12 x 768] tensor\n",
    "    # # where Y is the number of tokens in the sentence\n",
    "\n",
    "    # # loop over tokens in sentence\n",
    "    for token in token_embeddings:\n",
    "\n",
    "        # \"token\" is a [12 x 768] tensor\n",
    "\n",
    "        # sum the vectors from the last four layers\n",
    "        sum_vec = torch.sum(token[-4:], dim=0)\n",
    "        token_vecs_sum.append(sum_vec)\n",
    "\n",
    "    return token_vecs_sum\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "HhmbW-e-ROqO"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# Bert Embedding 前510字 （能运行）\\ndf['truncated'] = df['main_body'].apply(lambda x: x[:510] if len(x)>510 else x)\\ndf['bert_embedding'] = df['truncated'].apply(lambda x: get_bert_embeddings(x, bert_model, bert_tokenizer))\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# Bert Embedding 前510字 （能运行）\n",
    "df['truncated'] = df['main_body'].apply(lambda x: x[:510] if len(x)>510 else x)\n",
    "df['bert_embedding'] = df['truncated'].apply(lambda x: get_bert_embeddings(x, bert_model, bert_tokenizer))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "6D8nvab559NB"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom transformers import LongformerTokenizer, EncoderDecoderModel\\n\\n# Load model and tokenizer\\nlong_model = EncoderDecoderModel.from_pretrained(\"patrickvonplaten/longformer2roberta-cnn_dailymail-fp16\")\\nlong_tokenizer = LongformerTokenizer.from_pretrained(\"allenai/longformer-base-4096\") \\n\\ndef get_summary(text, model, tokenizer):\\n\\n    # Tokenize and summarize\\n    input_ids = tokenizer(text, return_tensors=\"pt\").input_ids\\n    output_ids = model.generate(input_ids)\\n\\n    # Get the summary from the output tokens\\n    summary = tokenizer.decode(output_ids[0], skip_special_tokens=True)\\n    \\n    return summary\\n\\ndf[\\'summary\\'] = df[\\'main_body\\'].apply(lambda x: get_summary(x, long_model, long_tokenizer) if len(x)>510 else x)   \\n'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 网上找的几种方法 但都经常报错（运行整个dataframe时）\n",
    "\n",
    "# 1 https://huggingface.co/facebook/bart-large-cnn\n",
    "\"\"\"\n",
    "from transformers import pipeline\n",
    "\n",
    "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "text = df['main_body'][3]\n",
    "summary = summarizer(text, max_length=510, min_length=50, do_sample=False)[0]['summary_text']\n",
    "print(summary)\n",
    "print(len(summary))\n",
    "\n",
    "df['summary'] = df['main_body'].apply(lambda x: summarizer(x, max_length=510, min_length=50, do_sample=False)[0]['summary_text'] if len(x)>510 else x)\n",
    "\"\"\"\n",
    "\n",
    "# 2 https://github.com/christianversloot/machine-learning-articles/blob/main/transformers-for-long-text-code-examples-with-longformer.md\n",
    "\"\"\"\n",
    "from transformers import LongformerTokenizer, EncoderDecoderModel\n",
    "\n",
    "# Load model and tokenizer\n",
    "long_model = EncoderDecoderModel.from_pretrained(\"patrickvonplaten/longformer2roberta-cnn_dailymail-fp16\")\n",
    "long_tokenizer = LongformerTokenizer.from_pretrained(\"allenai/longformer-base-4096\") \n",
    "\n",
    "def get_summary(text, model, tokenizer):\n",
    "\n",
    "    # Tokenize and summarize\n",
    "    input_ids = tokenizer(text, return_tensors=\"pt\").input_ids\n",
    "    output_ids = model.generate(input_ids)\n",
    "\n",
    "    # Get the summary from the output tokens\n",
    "    summary = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "    \n",
    "    return summary\n",
    "\n",
    "df['summary'] = df['main_body'].apply(lambda x: get_summary(x, long_model, long_tokenizer) if len(x)>510 else x)   \n",
    "\"\"\"\n",
    "\n",
    "# https://towardsdatascience.com/text-summarization-with-nlp-textrank-vs-seq2seq-vs-bart-474943efeb09"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "ei19T9aHAOQj"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nimport gensim\\nfrom nltk.tokenize import word_tokenize\\n\\n# Tokenize the text in the column\\ndf['tokenized_text'] = df['main_body'].apply(lambda x: word_tokenize(x))\\n\\nmodel = gensim.models.Word2Vec(df['tokenized_text'], vector_size=5000, window=5, min_count=1, workers=4)\\n\\ndf['embedding_vectors'] = df['tokenized_text'].apply(lambda x: [model.wv[word] for word in x])\\n\\ndf3 = pd.DataFrame(df['embedding_vectors'].tolist())\\ndf3\\n\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 试了word2vec 但df3里面的vector维度都不一样\n",
    "# 也试了下doc2vec 也不行\n",
    "# 有兴趣可以看下 https://towardsdatascience.com/how-to-vectorize-text-in-dataframes-for-nlp-tasks-3-simple-techniques-82925a5600db\n",
    "\"\"\"\n",
    "import gensim\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Tokenize the text in the column\n",
    "df['tokenized_text'] = df['main_body'].apply(lambda x: word_tokenize(x))\n",
    "\n",
    "model = gensim.models.Word2Vec(df['tokenized_text'], vector_size=5000, window=5, min_count=1, workers=4)\n",
    "\n",
    "df['embedding_vectors'] = df['tokenized_text'].apply(lambda x: [model.wv[word] for word in x])\n",
    "\n",
    "df3 = pd.DataFrame(df['embedding_vectors'].tolist())\n",
    "df3\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AANSjbcK-HU3"
   },
   "source": [
    "Bag of Words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "X7AfCnvN-FCk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words in transformed df:  51312\n"
     ]
    }
   ],
   "source": [
    "# Count how many times a word appears in the dataset\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "total_counts = Counter()\n",
    "for i in range(len(df['main_body'])):\n",
    "    for word in df['main_body'].values[i].split(\" \"):\n",
    "        total_counts[word] += 1\n",
    "\n",
    "print(\"Total words in transformed df: \", len(total_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "qvEDc-oi-FUP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 30 words:  \n",
      " ['number', 'university', 'language', 'paper', 'email', 'information', 'linguistics', 'address', 'use', 'de', 'one', 'conference', 'send', 'e', 'order', 'please', 'make', 'languages', 'english', 'include', 'work', 'mail', 'http', 'program', 'also', 'edu', 'new', 'would', 'name', 'may', 'fax']\n"
     ]
    }
   ],
   "source": [
    "# Sort in decreasing order (Word with highest frequency appears first)\n",
    "vocab = sorted(total_counts, key=total_counts.get, reverse=True)\n",
    "print('Top 30 words: ', '\\n', vocab[:31])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "xTjS-3w0-Fas"
   },
   "outputs": [],
   "source": [
    "# Map words to index\n",
    "vocab_size = len(vocab)\n",
    "word2idx = {}\n",
    "\n",
    "# print vocab_size\n",
    "for i, word in enumerate(vocab):\n",
    "    word2idx[word] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "uPgtnJsA-Fe2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2596, 51312)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a function to convert text to vectors\n",
    "def text_to_vector(text, vocab):\n",
    "    vector = np.zeros(len(vocab), dtype=np.int_)\n",
    "    for word in text.split():\n",
    "        if word in vocab:\n",
    "            index = vocab.index(word)\n",
    "            vector[index] += 1\n",
    "    return vector\n",
    "\n",
    "# Convert all text to vectors\n",
    "word_vectors = np.zeros((len(df['main_body']), len(vocab)), dtype=np.int_)\n",
    "\n",
    "for i, text in enumerate(df['main_body']):\n",
    "    word_vectors[i] = text_to_vector(text, vocab)\n",
    "    \n",
    "word_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "B-Q9ZzwR-Fkl"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>university</th>\n",
       "      <th>language</th>\n",
       "      <th>paper</th>\n",
       "      <th>email</th>\n",
       "      <th>information</th>\n",
       "      <th>linguistics</th>\n",
       "      <th>address</th>\n",
       "      <th>use</th>\n",
       "      <th>de</th>\n",
       "      <th>...</th>\n",
       "      <th>singledialect</th>\n",
       "      <th>corpuses</th>\n",
       "      <th>undescribed</th>\n",
       "      <th>cech</th>\n",
       "      <th>viktor</th>\n",
       "      <th>elsik</th>\n",
       "      <th>mozes</th>\n",
       "      <th>heinschink</th>\n",
       "      <th>hubschmannova</th>\n",
       "      <th>igla</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2591</th>\n",
       "      <td>158</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2592</th>\n",
       "      <td>36</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2593</th>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2594</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2595</th>\n",
       "      <td>49</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2596 rows × 51312 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      number  university  language  paper  email  information  linguistics  \\\n",
       "0         13           6         3      1      1            1            2   \n",
       "1         36           0         0      0      0            1            0   \n",
       "2         13           0         0      0      0            0            0   \n",
       "3          0           0         0      0      0            0            0   \n",
       "4          8           1         1      1      0            0            2   \n",
       "...      ...         ...       ...    ...    ...          ...          ...   \n",
       "2591     158          37         0      9      4            4            1   \n",
       "2592      36           5         3      7      9            1            0   \n",
       "2593      35           0         2      5      2            1            0   \n",
       "2594      18           1         5      0      1            0            0   \n",
       "2595      49           5        10      0      4            3            0   \n",
       "\n",
       "      address  use  de  ...  singledialect  corpuses  undescribed  cech  \\\n",
       "0           0    0   0  ...              0         0            0     0   \n",
       "1           1    0   0  ...              0         0            0     0   \n",
       "2           0    0   0  ...              0         0            0     0   \n",
       "3           0    0   0  ...              0         0            0     0   \n",
       "4           0    0   0  ...              0         0            0     0   \n",
       "...       ...  ...  ..  ...            ...       ...          ...   ...   \n",
       "2591        1    1   0  ...              0         0            0     0   \n",
       "2592        5    0   0  ...              0         0            0     0   \n",
       "2593        1    1   1  ...              0         0            0     0   \n",
       "2594        0    0   5  ...              0         0            0     0   \n",
       "2595        2    2   0  ...              1         1            1     1   \n",
       "\n",
       "      viktor  elsik  mozes  heinschink  hubschmannova  igla  \n",
       "0          0      0      0           0              0     0  \n",
       "1          0      0      0           0              0     0  \n",
       "2          0      0      0           0              0     0  \n",
       "3          0      0      0           0              0     0  \n",
       "4          0      0      0           0              0     0  \n",
       "...      ...    ...    ...         ...            ...   ...  \n",
       "2591       0      0      0           0              0     0  \n",
       "2592       0      0      0           0              0     0  \n",
       "2593       0      0      0           0              0     0  \n",
       "2594       0      0      0           0              0     0  \n",
       "2595       1      1      1           1              1     1  \n",
       "\n",
       "[2596 rows x 51312 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert transformed vectors to dataframe to visualize\n",
    "\n",
    "df2 = pd.DataFrame(word_vectors, columns=vocab)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "jDkG6ypU-Fpi"
   },
   "outputs": [],
   "source": [
    "# # apply SVD\n",
    "# from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# # n_components must be between 1 and min(vectors.shape)\n",
    "# svd = TruncatedSVD(n_components=500)\n",
    "# svd.fit(word_vectors)\n",
    "# print(svd.explained_variance_ratio_.sum()) #95%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "CMavljEA-Xsk"
   },
   "outputs": [],
   "source": [
    "# transformed_vectors = svd.transform(word_vectors)\n",
    "# print(transformed_vectors)\n",
    "# print(\"dimension =\", transformed_vectors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 降维后的\n",
    "# df2 = pd.DataFrame(transformed_vectors)\n",
    "# df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LbUsSm7pj4f-"
   },
   "source": [
    "# 分数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_val_X_tfidf, test_X_tfidf, train_val_y_tfidf, test_y_tfidf = train_test_split(df1, df['label'], test_size=0.2, random_state=42)\n",
    "train_X_tfidf, val_X_tfidf, train_y_tfidf, val_y_tfidf = train_test_split(train_val_X_tfidf, train_val_y_tfidf, test_size=0.25, random_state=42)\n",
    "\n",
    "train_val_X_bag, test_X_bag, train_val_y_bag, test_y_bag = train_test_split(df2, df['label'], test_size=0.2, random_state=42)\n",
    "train_X_bag, val_X_bag, train_y_bag, val_y_bag = train_test_split(train_val_X_bag, train_val_y_bag, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "TzAv5aDMj4f-"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aaa</th>\n",
       "      <th>aaai</th>\n",
       "      <th>aaainumbers</th>\n",
       "      <th>aaal</th>\n",
       "      <th>aaanumbers</th>\n",
       "      <th>aaarghh</th>\n",
       "      <th>aaas</th>\n",
       "      <th>aabb</th>\n",
       "      <th>aabyhoej</th>\n",
       "      <th>...</th>\n",
       "      <th>zwischen</th>\n",
       "      <th>zwitserlood</th>\n",
       "      <th>zxgahnumbersqabjh</th>\n",
       "      <th>zybatov</th>\n",
       "      <th>zybatow</th>\n",
       "      <th>zygmunt</th>\n",
       "      <th>zyokyoozyu</th>\n",
       "      <th>zytkow</th>\n",
       "      <th>zzlsa</th>\n",
       "      <th>zznumbers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1186</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1168</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2187</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1659</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>977</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1604</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1280</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1557 rows × 51294 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       aa  aaa  aaai  aaainumbers  aaal  aaanumbers  aaarghh  aaas  aabb  \\\n",
       "1186  0.0  0.0   0.0          0.0   0.0         0.0      0.0   0.0   0.0   \n",
       "1168  0.0  0.0   0.0          0.0   0.0         0.0      0.0   0.0   0.0   \n",
       "890   0.0  0.0   0.0          0.0   0.0         0.0      0.0   0.0   0.0   \n",
       "2187  0.0  0.0   0.0          0.0   0.0         0.0      0.0   0.0   0.0   \n",
       "1659  0.0  0.0   0.0          0.0   0.0         0.0      0.0   0.0   0.0   \n",
       "...   ...  ...   ...          ...   ...         ...      ...   ...   ...   \n",
       "977   0.0  0.0   0.0          0.0   0.0         0.0      0.0   0.0   0.0   \n",
       "615   0.0  0.0   0.0          0.0   0.0         0.0      0.0   0.0   0.0   \n",
       "1604  0.0  0.0   0.0          0.0   0.0         0.0      0.0   0.0   0.0   \n",
       "1280  0.0  0.0   0.0          0.0   0.0         0.0      0.0   0.0   0.0   \n",
       "734   0.0  0.0   0.0          0.0   0.0         0.0      0.0   0.0   0.0   \n",
       "\n",
       "      aabyhoej  ...  zwischen  zwitserlood  zxgahnumbersqabjh  zybatov  \\\n",
       "1186       0.0  ...       0.0          0.0                0.0      0.0   \n",
       "1168       0.0  ...       0.0          0.0                0.0      0.0   \n",
       "890        0.0  ...       0.0          0.0                0.0      0.0   \n",
       "2187       0.0  ...       0.0          0.0                0.0      0.0   \n",
       "1659       0.0  ...       0.0          0.0                0.0      0.0   \n",
       "...        ...  ...       ...          ...                ...      ...   \n",
       "977        0.0  ...       0.0          0.0                0.0      0.0   \n",
       "615        0.0  ...       0.0          0.0                0.0      0.0   \n",
       "1604       0.0  ...       0.0          0.0                0.0      0.0   \n",
       "1280       0.0  ...       0.0          0.0                0.0      0.0   \n",
       "734        0.0  ...       0.0          0.0                0.0      0.0   \n",
       "\n",
       "      zybatow  zygmunt  zyokyoozyu  zytkow  zzlsa  zznumbers  \n",
       "1186      0.0      0.0         0.0     0.0    0.0        0.0  \n",
       "1168      0.0      0.0         0.0     0.0    0.0        0.0  \n",
       "890       0.0      0.0         0.0     0.0    0.0        0.0  \n",
       "2187      0.0      0.0         0.0     0.0    0.0        0.0  \n",
       "1659      0.0      0.0         0.0     0.0    0.0        0.0  \n",
       "...       ...      ...         ...     ...    ...        ...  \n",
       "977       0.0      0.0         0.0     0.0    0.0        0.0  \n",
       "615       0.0      0.0         0.0     0.0    0.0        0.0  \n",
       "1604      0.0      0.0         0.0     0.0    0.0        0.0  \n",
       "1280      0.0      0.0         0.0     0.0    0.0        0.0  \n",
       "734       0.0      0.0         0.0     0.0    0.0        0.0  \n",
       "\n",
       "[1557 rows x 51294 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "0FzwzXTij4f_"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aaa</th>\n",
       "      <th>aaai</th>\n",
       "      <th>aaainumbers</th>\n",
       "      <th>aaal</th>\n",
       "      <th>aaanumbers</th>\n",
       "      <th>aaarghh</th>\n",
       "      <th>aaas</th>\n",
       "      <th>aabb</th>\n",
       "      <th>aabyhoej</th>\n",
       "      <th>...</th>\n",
       "      <th>zwischen</th>\n",
       "      <th>zwitserlood</th>\n",
       "      <th>zxgahnumbersqabjh</th>\n",
       "      <th>zybatov</th>\n",
       "      <th>zybatow</th>\n",
       "      <th>zygmunt</th>\n",
       "      <th>zyokyoozyu</th>\n",
       "      <th>zytkow</th>\n",
       "      <th>zzlsa</th>\n",
       "      <th>zznumbers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>834</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1477</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2562</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1924</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2378</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>519 rows × 51294 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       aa  aaa  aaai  aaainumbers  aaal  aaanumbers  aaarghh  aaas  aabb  \\\n",
       "834   0.0  0.0   0.0          0.0   0.0         0.0      0.0   0.0   0.0   \n",
       "142   0.0  0.0   0.0          0.0   0.0         0.0      0.0   0.0   0.0   \n",
       "1477  0.0  0.0   0.0          0.0   0.0         0.0      0.0   0.0   0.0   \n",
       "185   0.0  0.0   0.0          0.0   0.0         0.0      0.0   0.0   0.0   \n",
       "2562  0.0  0.0   0.0          0.0   0.0         0.0      0.0   0.0   0.0   \n",
       "...   ...  ...   ...          ...   ...         ...      ...   ...   ...   \n",
       "1924  0.0  0.0   0.0          0.0   0.0         0.0      0.0   0.0   0.0   \n",
       "97    0.0  0.0   0.0          0.0   0.0         0.0      0.0   0.0   0.0   \n",
       "271   0.0  0.0   0.0          0.0   0.0         0.0      0.0   0.0   0.0   \n",
       "2378  0.0  0.0   0.0          0.0   0.0         0.0      0.0   0.0   0.0   \n",
       "888   0.0  0.0   0.0          0.0   0.0         0.0      0.0   0.0   0.0   \n",
       "\n",
       "      aabyhoej  ...  zwischen  zwitserlood  zxgahnumbersqabjh  zybatov  \\\n",
       "834        0.0  ...       0.0          0.0                0.0      0.0   \n",
       "142        0.0  ...       0.0          0.0                0.0      0.0   \n",
       "1477       0.0  ...       0.0          0.0                0.0      0.0   \n",
       "185        0.0  ...       0.0          0.0                0.0      0.0   \n",
       "2562       0.0  ...       0.0          0.0                0.0      0.0   \n",
       "...        ...  ...       ...          ...                ...      ...   \n",
       "1924       0.0  ...       0.0          0.0                0.0      0.0   \n",
       "97         0.0  ...       0.0          0.0                0.0      0.0   \n",
       "271        0.0  ...       0.0          0.0                0.0      0.0   \n",
       "2378       0.0  ...       0.0          0.0                0.0      0.0   \n",
       "888        0.0  ...       0.0          0.0                0.0      0.0   \n",
       "\n",
       "      zybatow  zygmunt  zyokyoozyu  zytkow  zzlsa  zznumbers  \n",
       "834       0.0      0.0         0.0     0.0    0.0        0.0  \n",
       "142       0.0      0.0         0.0     0.0    0.0        0.0  \n",
       "1477      0.0      0.0         0.0     0.0    0.0        0.0  \n",
       "185       0.0      0.0         0.0     0.0    0.0        0.0  \n",
       "2562      0.0      0.0         0.0     0.0    0.0        0.0  \n",
       "...       ...      ...         ...     ...    ...        ...  \n",
       "1924      0.0      0.0         0.0     0.0    0.0        0.0  \n",
       "97        0.0      0.0         0.0     0.0    0.0        0.0  \n",
       "271       0.0      0.0         0.0     0.0    0.0        0.0  \n",
       "2378      0.0      0.0         0.0     0.0    0.0        0.0  \n",
       "888       0.0      0.0         0.0     0.0    0.0        0.0  \n",
       "\n",
       "[519 rows x 51294 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_X_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aaa</th>\n",
       "      <th>aaai</th>\n",
       "      <th>aaainumbers</th>\n",
       "      <th>aaal</th>\n",
       "      <th>aaanumbers</th>\n",
       "      <th>aaarghh</th>\n",
       "      <th>aaas</th>\n",
       "      <th>aabb</th>\n",
       "      <th>aabyhoej</th>\n",
       "      <th>...</th>\n",
       "      <th>zwischen</th>\n",
       "      <th>zwitserlood</th>\n",
       "      <th>zxgahnumbersqabjh</th>\n",
       "      <th>zybatov</th>\n",
       "      <th>zybatow</th>\n",
       "      <th>zygmunt</th>\n",
       "      <th>zyokyoozyu</th>\n",
       "      <th>zytkow</th>\n",
       "      <th>zzlsa</th>\n",
       "      <th>zznumbers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2122</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1739</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2421</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1670</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1113</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>845</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>520 rows × 51294 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       aa  aaa  aaai  aaainumbers  aaal  aaanumbers  aaarghh  aaas  aabb  \\\n",
       "211   0.0  0.0   0.0          0.0   0.0         0.0      0.0   0.0   0.0   \n",
       "2122  0.0  0.0   0.0          0.0   0.0         0.0      0.0   0.0   0.0   \n",
       "1739  0.0  0.0   0.0          0.0   0.0         0.0      0.0   0.0   0.0   \n",
       "2421  0.0  0.0   0.0          0.0   0.0         0.0      0.0   0.0   0.0   \n",
       "1670  0.0  0.0   0.0          0.0   0.0         0.0      0.0   0.0   0.0   \n",
       "...   ...  ...   ...          ...   ...         ...      ...   ...   ...   \n",
       "49    0.0  0.0   0.0          0.0   0.0         0.0      0.0   0.0   0.0   \n",
       "700   0.0  0.0   0.0          0.0   0.0         0.0      0.0   0.0   0.0   \n",
       "1113  0.0  0.0   0.0          0.0   0.0         0.0      0.0   0.0   0.0   \n",
       "48    0.0  0.0   0.0          0.0   0.0         0.0      0.0   0.0   0.0   \n",
       "845   0.0  0.0   0.0          0.0   0.0         0.0      0.0   0.0   0.0   \n",
       "\n",
       "      aabyhoej  ...  zwischen  zwitserlood  zxgahnumbersqabjh  zybatov  \\\n",
       "211        0.0  ...       0.0          0.0                0.0      0.0   \n",
       "2122       0.0  ...       0.0          0.0                0.0      0.0   \n",
       "1739       0.0  ...       0.0          0.0                0.0      0.0   \n",
       "2421       0.0  ...       0.0          0.0                0.0      0.0   \n",
       "1670       0.0  ...       0.0          0.0                0.0      0.0   \n",
       "...        ...  ...       ...          ...                ...      ...   \n",
       "49         0.0  ...       0.0          0.0                0.0      0.0   \n",
       "700        0.0  ...       0.0          0.0                0.0      0.0   \n",
       "1113       0.0  ...       0.0          0.0                0.0      0.0   \n",
       "48         0.0  ...       0.0          0.0                0.0      0.0   \n",
       "845        0.0  ...       0.0          0.0                0.0      0.0   \n",
       "\n",
       "      zybatow  zygmunt  zyokyoozyu  zytkow  zzlsa  zznumbers  \n",
       "211       0.0      0.0         0.0     0.0    0.0        0.0  \n",
       "2122      0.0      0.0         0.0     0.0    0.0        0.0  \n",
       "1739      0.0      0.0         0.0     0.0    0.0        0.0  \n",
       "2421      0.0      0.0         0.0     0.0    0.0        0.0  \n",
       "1670      0.0      0.0         0.0     0.0    0.0        0.0  \n",
       "...       ...      ...         ...     ...    ...        ...  \n",
       "49        0.0      0.0         0.0     0.0    0.0        0.0  \n",
       "700       0.0      0.0         0.0     0.0    0.0        0.0  \n",
       "1113      0.0      0.0         0.0     0.0    0.0        0.0  \n",
       "48        0.0      0.0         0.0     0.0    0.0        0.0  \n",
       "845       0.0      0.0         0.0     0.0    0.0        0.0  \n",
       "\n",
       "[520 rows x 51294 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1325    0\n",
       "1307    1\n",
       "1000    0\n",
       "2416    0\n",
       "1841    0\n",
       "       ..\n",
       "1105    0\n",
       "692     0\n",
       "1778    0\n",
       "1423    0\n",
       "821     0\n",
       "Name: label, Length: 1557, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "934     0\n",
       "159     0\n",
       "1638    1\n",
       "206     0\n",
       "2854    0\n",
       "       ..\n",
       "2130    0\n",
       "108     0\n",
       "301     0\n",
       "2637    0\n",
       "998     0\n",
       "Name: label, Length: 519, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_y_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "233     0\n",
       "2342    0\n",
       "1933    0\n",
       "2689    1\n",
       "1853    0\n",
       "       ..\n",
       "52      0\n",
       "781     0\n",
       "1248    0\n",
       "51      1\n",
       "945     0\n",
       "Name: label, Length: 520, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>university</th>\n",
       "      <th>language</th>\n",
       "      <th>paper</th>\n",
       "      <th>email</th>\n",
       "      <th>information</th>\n",
       "      <th>linguistics</th>\n",
       "      <th>address</th>\n",
       "      <th>use</th>\n",
       "      <th>de</th>\n",
       "      <th>...</th>\n",
       "      <th>singledialect</th>\n",
       "      <th>corpuses</th>\n",
       "      <th>undescribed</th>\n",
       "      <th>cech</th>\n",
       "      <th>viktor</th>\n",
       "      <th>elsik</th>\n",
       "      <th>mozes</th>\n",
       "      <th>heinschink</th>\n",
       "      <th>hubschmannova</th>\n",
       "      <th>igla</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1186</th>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1168</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>47</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2187</th>\n",
       "      <td>24</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1659</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>977</th>\n",
       "      <td>25</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1604</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1280</th>\n",
       "      <td>52</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734</th>\n",
       "      <td>26</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1557 rows × 51312 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      number  university  language  paper  email  information  linguistics  \\\n",
       "1186      30           2         1      0      3            0            1   \n",
       "1168       0           0         0      0      0            0            0   \n",
       "890       47          10         5      0      0            0            1   \n",
       "2187      24           5         2      4      1            0            0   \n",
       "1659       0           1         3      0      0            0            1   \n",
       "...      ...         ...       ...    ...    ...          ...          ...   \n",
       "977       25           6         0      3      2            1            2   \n",
       "615        0           1         1      0      0            0            0   \n",
       "1604       9           0         0      0      1            0            0   \n",
       "1280      52           7         4     16      1            3            7   \n",
       "734       26           2         1      4      1            0            0   \n",
       "\n",
       "      address  use  de  ...  singledialect  corpuses  undescribed  cech  \\\n",
       "1186        0    0   2  ...              0         0            0     0   \n",
       "1168        0    0   0  ...              0         0            0     0   \n",
       "890         1    0   0  ...              0         0            0     0   \n",
       "2187        3    0   0  ...              0         0            0     0   \n",
       "1659        0    1   0  ...              0         0            0     0   \n",
       "...       ...  ...  ..  ...            ...       ...          ...   ...   \n",
       "977         2    0   0  ...              0         0            0     0   \n",
       "615         0    0   0  ...              0         0            0     0   \n",
       "1604        0    0   0  ...              0         0            0     0   \n",
       "1280        5    2   3  ...              0         0            0     0   \n",
       "734         2    1   0  ...              0         0            0     0   \n",
       "\n",
       "      viktor  elsik  mozes  heinschink  hubschmannova  igla  \n",
       "1186       0      0      0           0              0     0  \n",
       "1168       0      0      0           0              0     0  \n",
       "890        0      0      0           0              0     0  \n",
       "2187       0      0      0           0              0     0  \n",
       "1659       0      0      0           0              0     0  \n",
       "...      ...    ...    ...         ...            ...   ...  \n",
       "977        0      0      0           0              0     0  \n",
       "615        0      0      0           0              0     0  \n",
       "1604       0      0      0           0              0     0  \n",
       "1280       0      0      0           0              0     0  \n",
       "734        0      0      0           0              0     0  \n",
       "\n",
       "[1557 rows x 51312 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X_bag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>university</th>\n",
       "      <th>language</th>\n",
       "      <th>paper</th>\n",
       "      <th>email</th>\n",
       "      <th>information</th>\n",
       "      <th>linguistics</th>\n",
       "      <th>address</th>\n",
       "      <th>use</th>\n",
       "      <th>de</th>\n",
       "      <th>...</th>\n",
       "      <th>singledialect</th>\n",
       "      <th>corpuses</th>\n",
       "      <th>undescribed</th>\n",
       "      <th>cech</th>\n",
       "      <th>viktor</th>\n",
       "      <th>elsik</th>\n",
       "      <th>mozes</th>\n",
       "      <th>heinschink</th>\n",
       "      <th>hubschmannova</th>\n",
       "      <th>igla</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>834</th>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1477</th>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2562</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1924</th>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2378</th>\n",
       "      <td>36</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>519 rows × 51312 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      number  university  language  paper  email  information  linguistics  \\\n",
       "834       16           2         0      0      0            1            5   \n",
       "142        1           0         0      0      0            0            1   \n",
       "1477      36           0         0      0      2            9            0   \n",
       "185        1           0         1      0      0            0            0   \n",
       "2562       0           1         4      0      0            0            0   \n",
       "...      ...         ...       ...    ...    ...          ...          ...   \n",
       "1924      18           0         0      0      0            1            0   \n",
       "97         0           0         0      0      0            0            0   \n",
       "271       20           0         0      1      2            0            0   \n",
       "2378      36           3         0      6      3            1            4   \n",
       "888        6           1         1      0      0            2            0   \n",
       "\n",
       "      address  use  de  ...  singledialect  corpuses  undescribed  cech  \\\n",
       "834         1    0   0  ...              0         0            0     0   \n",
       "142         0    0   0  ...              0         0            0     0   \n",
       "1477        5    4   0  ...              0         0            0     0   \n",
       "185         0    0   0  ...              0         0            0     0   \n",
       "2562        0    0   2  ...              0         0            0     0   \n",
       "...       ...  ...  ..  ...            ...       ...          ...   ...   \n",
       "1924        0    2   0  ...              0         0            0     0   \n",
       "97          0    0   1  ...              0         0            0     0   \n",
       "271         0    0   2  ...              0         0            0     0   \n",
       "2378        2    0   0  ...              0         0            0     0   \n",
       "888         0    0   0  ...              0         0            0     0   \n",
       "\n",
       "      viktor  elsik  mozes  heinschink  hubschmannova  igla  \n",
       "834        0      0      0           0              0     0  \n",
       "142        0      0      0           0              0     0  \n",
       "1477       0      0      0           0              0     0  \n",
       "185        0      0      0           0              0     0  \n",
       "2562       0      0      0           0              0     0  \n",
       "...      ...    ...    ...         ...            ...   ...  \n",
       "1924       0      0      0           0              0     0  \n",
       "97         0      0      0           0              0     0  \n",
       "271        0      0      0           0              0     0  \n",
       "2378       0      0      0           0              0     0  \n",
       "888        0      0      0           0              0     0  \n",
       "\n",
       "[519 rows x 51312 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_X_bag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>university</th>\n",
       "      <th>language</th>\n",
       "      <th>paper</th>\n",
       "      <th>email</th>\n",
       "      <th>information</th>\n",
       "      <th>linguistics</th>\n",
       "      <th>address</th>\n",
       "      <th>use</th>\n",
       "      <th>de</th>\n",
       "      <th>...</th>\n",
       "      <th>singledialect</th>\n",
       "      <th>corpuses</th>\n",
       "      <th>undescribed</th>\n",
       "      <th>cech</th>\n",
       "      <th>viktor</th>\n",
       "      <th>elsik</th>\n",
       "      <th>mozes</th>\n",
       "      <th>heinschink</th>\n",
       "      <th>hubschmannova</th>\n",
       "      <th>igla</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>48</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2122</th>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1739</th>\n",
       "      <td>35</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2421</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1670</th>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>86</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700</th>\n",
       "      <td>44</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1113</th>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>845</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>520 rows × 51312 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      number  university  language  paper  email  information  linguistics  \\\n",
       "211       48           4         2      0      0            1            1   \n",
       "2122      38           1         2      3      4            0            0   \n",
       "1739      35           5         3      7      9            1            0   \n",
       "2421       4           0         0      0      0            0            0   \n",
       "1670      28           1         2      3      2            6            2   \n",
       "...      ...         ...       ...    ...    ...          ...          ...   \n",
       "49        86           4         2      0      0            4            3   \n",
       "700       44           6         2      4      0            1            2   \n",
       "1113      27           0         0      1      1            0            1   \n",
       "48        68           0         0      2     10            1            0   \n",
       "845        0           0         0      0      0            0            0   \n",
       "\n",
       "      address  use  de  ...  singledialect  corpuses  undescribed  cech  \\\n",
       "211         0    0   0  ...              0         0            0     0   \n",
       "2122        2    4   0  ...              0         0            0     0   \n",
       "1739        5    0   0  ...              0         0            0     0   \n",
       "2421        0    1   0  ...              0         0            0     0   \n",
       "1670        3    1   2  ...              0         0            0     0   \n",
       "...       ...  ...  ..  ...            ...       ...          ...   ...   \n",
       "49          0    2   2  ...              0         0            0     0   \n",
       "700         0    0   0  ...              0         0            0     0   \n",
       "1113        0    0   6  ...              0         0            0     0   \n",
       "48          3    0   0  ...              0         0            0     0   \n",
       "845         0    0   0  ...              0         0            0     0   \n",
       "\n",
       "      viktor  elsik  mozes  heinschink  hubschmannova  igla  \n",
       "211        0      0      0           0              0     0  \n",
       "2122       0      0      0           0              0     0  \n",
       "1739       0      0      0           0              0     0  \n",
       "2421       0      0      0           0              0     0  \n",
       "1670       0      0      0           0              0     0  \n",
       "...      ...    ...    ...         ...            ...   ...  \n",
       "49         0      0      0           0              0     0  \n",
       "700        0      0      0           0              0     0  \n",
       "1113       0      0      0           0              0     0  \n",
       "48         0      0      0           0              0     0  \n",
       "845        0      0      0           0              0     0  \n",
       "\n",
       "[520 rows x 51312 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X_bag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1325    0\n",
       "1307    1\n",
       "1000    0\n",
       "2416    0\n",
       "1841    0\n",
       "       ..\n",
       "1105    0\n",
       "692     0\n",
       "1778    0\n",
       "1423    0\n",
       "821     0\n",
       "Name: label, Length: 1557, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y_bag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "934     0\n",
       "159     0\n",
       "1638    1\n",
       "206     0\n",
       "2854    0\n",
       "       ..\n",
       "2130    0\n",
       "108     0\n",
       "301     0\n",
       "2637    0\n",
       "998     0\n",
       "Name: label, Length: 519, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_y_bag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "233     0\n",
       "2342    0\n",
       "1933    0\n",
       "2689    1\n",
       "1853    0\n",
       "       ..\n",
       "52      0\n",
       "781     0\n",
       "1248    0\n",
       "51      1\n",
       "945     0\n",
       "Name: label, Length: 520, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y_bag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification by Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF + Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=0)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(random_state = 0) \n",
    "rf.fit( train_X_tfidf, train_y_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=0)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_bag = RandomForestClassifier(random_state = 0) \n",
    "rf_bag.fit( train_X_bag, train_y_bag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "predic_tfidf = rf.predict(val_X_tfidf)\n",
    "predic_bag = rf_bag.predict(val_X_bag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mesure for tf-idf feature\n",
    "accuracy_tfdif_ori = accuracy_score(predic_tfidf,val_y_tfidf)\n",
    "f1_tfidf_ori = f1_score(predic_tfidf,val_y_tfidf)\n",
    "cm_tfidf_ori = confusion_matrix(predic_tfidf,val_y_tfidf)\n",
    "\n",
    "#mesure for BOW feature\n",
    "accuracy_bag_ori = accuracy_score(predic_bag,val_y_bag)\n",
    "f1_bag_ori = f1_score(predic_bag,val_y_bag)\n",
    "cm_bag_ori = confusion_matrix(predic_bag,val_y_bag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mesure for tf-idf feature with original model:\n",
      "accuracy is        : 0.9691714836223507\n",
      "f1 is              : 0.8750000000000001\n",
      "confusion matrix is:\n",
      " [[447  16]\n",
      " [  0  56]]\n"
     ]
    }
   ],
   "source": [
    "print('mesure for tf-idf feature with original model:')\n",
    "print('accuracy is        :',accuracy_tfdif_ori)\n",
    "print('f1 is              :',f1_tfidf_ori)\n",
    "print('confusion matrix is:\\n',cm_tfidf_ori)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mesure for BOW feature with original model:\n",
      "accuracy is        : 0.9730250481695568\n",
      "f1 is              : 0.893939393939394\n",
      "confusion matrix is:\n",
      " [[446  13]\n",
      " [  1  59]]\n"
     ]
    }
   ],
   "source": [
    "print('mesure for BOW feature with original model:')\n",
    "print('accuracy is        :',accuracy_bag_ori)\n",
    "print('f1 is              :',f1_bag_ori)\n",
    "print('confusion matrix is:\\n',cm_bag_ori)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'auto',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': 0,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'auto',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': 0,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_bag.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimize the RF model by several hyperparameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### the model with tf-idf feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Possible Models 144\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "params_grid = {\n",
    "                'n_estimators':[100,200,400,800],\n",
    "               'max_depth':[5,15,25],\n",
    "                'min_samples_split' :[2,3,4,5],\n",
    "               'min_samples_leaf': [1,10,20],\n",
    "#                'min_weight_fraction_leaf': [0.0,0.25,0.5] #best performance got from 0.0\n",
    "              }\n",
    "grid = ParameterGrid(params_grid)\n",
    "cnt = 0\n",
    "for p in grid:\n",
    "    cnt = cnt+1\n",
    "\n",
    "print('Total Possible Models',cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "F1 score is------------------------------------ 0.9343065693430657\n",
      "{'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "F1 score is------------------------------------ 0.9428571428571428\n",
      "{'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 400}\n",
      "F1 score is------------------------------------ 0.9352517985611511\n",
      "{'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 800}\n",
      "F1 score is------------------------------------ 0.949640287769784\n",
      "{'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 100}\n",
      "F1 score is------------------------------------ 0.9343065693430657\n",
      "{'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 200}\n",
      "F1 score is------------------------------------ 0.9428571428571428\n",
      "{'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 400}\n",
      "F1 score is------------------------------------ 0.9352517985611511\n",
      "{'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 800}\n",
      "F1 score is------------------------------------ 0.949640287769784\n",
      "{'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 100}\n",
      "F1 score is------------------------------------ 0.9343065693430657\n",
      "{'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 200}\n",
      "F1 score is------------------------------------ 0.9428571428571428\n",
      "{'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 400}\n",
      "F1 score is------------------------------------ 0.9352517985611511\n",
      "{'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 800}\n",
      "F1 score is------------------------------------ 0.949640287769784\n",
      "{'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "F1 score is------------------------------------ 0.9343065693430657\n",
      "{'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 200}\n",
      "F1 score is------------------------------------ 0.9428571428571428\n",
      "{'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 400}\n",
      "F1 score is------------------------------------ 0.9352517985611511\n",
      "{'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 800}\n",
      "F1 score is------------------------------------ 0.949640287769784\n",
      "{'max_depth': 5, 'min_samples_leaf': 10, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "F1 score is------------------------------------ 0.9219858156028369\n",
      "{'max_depth': 5, 'min_samples_leaf': 10, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "F1 score is------------------------------------ 0.9361702127659574\n",
      "{'max_depth': 5, 'min_samples_leaf': 10, 'min_samples_split': 2, 'n_estimators': 400}\n",
      "F1 score is------------------------------------ 0.9285714285714286\n",
      "{'max_depth': 5, 'min_samples_leaf': 10, 'min_samples_split': 2, 'n_estimators': 800}\n",
      "F1 score is------------------------------------ 0.9503546099290779\n",
      "{'max_depth': 5, 'min_samples_leaf': 10, 'min_samples_split': 3, 'n_estimators': 100}\n",
      "F1 score is------------------------------------ 0.9219858156028369\n",
      "{'max_depth': 5, 'min_samples_leaf': 10, 'min_samples_split': 3, 'n_estimators': 200}\n",
      "F1 score is------------------------------------ 0.9361702127659574\n",
      "{'max_depth': 5, 'min_samples_leaf': 10, 'min_samples_split': 3, 'n_estimators': 400}\n",
      "F1 score is------------------------------------ 0.9285714285714286\n",
      "{'max_depth': 5, 'min_samples_leaf': 10, 'min_samples_split': 3, 'n_estimators': 800}\n",
      "F1 score is------------------------------------ 0.9503546099290779\n",
      "{'max_depth': 5, 'min_samples_leaf': 10, 'min_samples_split': 4, 'n_estimators': 100}\n",
      "F1 score is------------------------------------ 0.9219858156028369\n",
      "{'max_depth': 5, 'min_samples_leaf': 10, 'min_samples_split': 4, 'n_estimators': 200}\n",
      "F1 score is------------------------------------ 0.9361702127659574\n",
      "{'max_depth': 5, 'min_samples_leaf': 10, 'min_samples_split': 4, 'n_estimators': 400}\n",
      "F1 score is------------------------------------ 0.9285714285714286\n",
      "{'max_depth': 5, 'min_samples_leaf': 10, 'min_samples_split': 4, 'n_estimators': 800}\n",
      "F1 score is------------------------------------ 0.9503546099290779\n",
      "{'max_depth': 5, 'min_samples_leaf': 10, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "F1 score is------------------------------------ 0.9219858156028369\n",
      "{'max_depth': 5, 'min_samples_leaf': 10, 'min_samples_split': 5, 'n_estimators': 200}\n",
      "F1 score is------------------------------------ 0.9361702127659574\n",
      "{'max_depth': 5, 'min_samples_leaf': 10, 'min_samples_split': 5, 'n_estimators': 400}\n",
      "F1 score is------------------------------------ 0.9285714285714286\n",
      "{'max_depth': 5, 'min_samples_leaf': 10, 'min_samples_split': 5, 'n_estimators': 800}\n",
      "F1 score is------------------------------------ 0.9503546099290779\n",
      "{'max_depth': 5, 'min_samples_leaf': 20, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "F1 score is------------------------------------ 0.896551724137931\n",
      "{'max_depth': 5, 'min_samples_leaf': 20, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "F1 score is------------------------------------ 0.9315068493150684\n",
      "{'max_depth': 5, 'min_samples_leaf': 20, 'min_samples_split': 2, 'n_estimators': 400}\n",
      "F1 score is------------------------------------ 0.9379310344827586\n",
      "{'max_depth': 5, 'min_samples_leaf': 20, 'min_samples_split': 2, 'n_estimators': 800}\n",
      "F1 score is------------------------------------ 0.9379310344827586\n",
      "{'max_depth': 5, 'min_samples_leaf': 20, 'min_samples_split': 3, 'n_estimators': 100}\n",
      "F1 score is------------------------------------ 0.896551724137931\n",
      "{'max_depth': 5, 'min_samples_leaf': 20, 'min_samples_split': 3, 'n_estimators': 200}\n",
      "F1 score is------------------------------------ 0.9315068493150684\n",
      "{'max_depth': 5, 'min_samples_leaf': 20, 'min_samples_split': 3, 'n_estimators': 400}\n",
      "F1 score is------------------------------------ 0.9379310344827586\n",
      "{'max_depth': 5, 'min_samples_leaf': 20, 'min_samples_split': 3, 'n_estimators': 800}\n",
      "F1 score is------------------------------------ 0.9379310344827586\n",
      "{'max_depth': 5, 'min_samples_leaf': 20, 'min_samples_split': 4, 'n_estimators': 100}\n",
      "F1 score is------------------------------------ 0.896551724137931\n",
      "{'max_depth': 5, 'min_samples_leaf': 20, 'min_samples_split': 4, 'n_estimators': 200}\n",
      "F1 score is------------------------------------ 0.9315068493150684\n",
      "{'max_depth': 5, 'min_samples_leaf': 20, 'min_samples_split': 4, 'n_estimators': 400}\n",
      "F1 score is------------------------------------ 0.9379310344827586\n",
      "{'max_depth': 5, 'min_samples_leaf': 20, 'min_samples_split': 4, 'n_estimators': 800}\n",
      "F1 score is------------------------------------ 0.9379310344827586\n",
      "{'max_depth': 5, 'min_samples_leaf': 20, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "F1 score is------------------------------------ 0.896551724137931\n",
      "{'max_depth': 5, 'min_samples_leaf': 20, 'min_samples_split': 5, 'n_estimators': 200}\n",
      "F1 score is------------------------------------ 0.9315068493150684\n",
      "{'max_depth': 5, 'min_samples_leaf': 20, 'min_samples_split': 5, 'n_estimators': 400}\n",
      "F1 score is------------------------------------ 0.9379310344827586\n",
      "{'max_depth': 5, 'min_samples_leaf': 20, 'min_samples_split': 5, 'n_estimators': 800}\n",
      "F1 score is------------------------------------ 0.9379310344827586\n",
      "{'max_depth': 15, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "F1 score is------------------------------------ 0.9645390070921985\n",
      "{'max_depth': 15, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "F1 score is------------------------------------ 0.9645390070921985\n",
      "{'max_depth': 15, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 400}\n",
      "F1 score is------------------------------------ 0.9645390070921985\n",
      "{'max_depth': 15, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 800}\n",
      "F1 score is------------------------------------ 0.9645390070921985\n",
      "{'max_depth': 15, 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 100}\n",
      "F1 score is------------------------------------ 0.9577464788732395\n",
      "{'max_depth': 15, 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 200}\n",
      "F1 score is------------------------------------ 0.9645390070921985\n",
      "{'max_depth': 15, 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 400}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score is------------------------------------ 0.9640287769784173\n",
      "{'max_depth': 15, 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 800}\n",
      "F1 score is------------------------------------ 0.9714285714285714\n",
      "{'max_depth': 15, 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 100}\n",
      "F1 score is------------------------------------ 0.9645390070921985\n",
      "{'max_depth': 15, 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 200}\n",
      "F1 score is------------------------------------ 0.9645390070921985\n",
      "{'max_depth': 15, 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 400}\n",
      "F1 score is------------------------------------ 0.9640287769784173\n",
      "{'max_depth': 15, 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 800}\n",
      "F1 score is------------------------------------ 0.9571428571428572\n",
      "{'max_depth': 15, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "F1 score is------------------------------------ 0.9714285714285714\n",
      "{'max_depth': 15, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 200}\n",
      "F1 score is------------------------------------ 0.9645390070921985\n",
      "{'max_depth': 15, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 400}\n",
      "F1 score is------------------------------------ 0.9640287769784173\n",
      "{'max_depth': 15, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 800}\n",
      "F1 score is------------------------------------ 0.9640287769784173\n",
      "{'max_depth': 15, 'min_samples_leaf': 10, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "F1 score is------------------------------------ 0.9583333333333334\n",
      "{'max_depth': 15, 'min_samples_leaf': 10, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "F1 score is------------------------------------ 0.9594594594594595\n",
      "{'max_depth': 15, 'min_samples_leaf': 10, 'min_samples_split': 2, 'n_estimators': 400}\n",
      "F1 score is------------------------------------ 0.9594594594594595\n",
      "{'max_depth': 15, 'min_samples_leaf': 10, 'min_samples_split': 2, 'n_estimators': 800}\n",
      "F1 score is------------------------------------ 0.9659863945578231\n",
      "{'max_depth': 15, 'min_samples_leaf': 10, 'min_samples_split': 3, 'n_estimators': 100}\n",
      "F1 score is------------------------------------ 0.9583333333333334\n",
      "{'max_depth': 15, 'min_samples_leaf': 10, 'min_samples_split': 3, 'n_estimators': 200}\n",
      "F1 score is------------------------------------ 0.9594594594594595\n",
      "{'max_depth': 15, 'min_samples_leaf': 10, 'min_samples_split': 3, 'n_estimators': 400}\n",
      "F1 score is------------------------------------ 0.9594594594594595\n",
      "{'max_depth': 15, 'min_samples_leaf': 10, 'min_samples_split': 3, 'n_estimators': 800}\n",
      "F1 score is------------------------------------ 0.9659863945578231\n",
      "{'max_depth': 15, 'min_samples_leaf': 10, 'min_samples_split': 4, 'n_estimators': 100}\n",
      "F1 score is------------------------------------ 0.9583333333333334\n",
      "{'max_depth': 15, 'min_samples_leaf': 10, 'min_samples_split': 4, 'n_estimators': 200}\n",
      "F1 score is------------------------------------ 0.9594594594594595\n",
      "{'max_depth': 15, 'min_samples_leaf': 10, 'min_samples_split': 4, 'n_estimators': 400}\n",
      "F1 score is------------------------------------ 0.9594594594594595\n",
      "{'max_depth': 15, 'min_samples_leaf': 10, 'min_samples_split': 4, 'n_estimators': 800}\n",
      "F1 score is------------------------------------ 0.9659863945578231\n",
      "{'max_depth': 15, 'min_samples_leaf': 10, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "F1 score is------------------------------------ 0.9583333333333334\n",
      "{'max_depth': 15, 'min_samples_leaf': 10, 'min_samples_split': 5, 'n_estimators': 200}\n",
      "F1 score is------------------------------------ 0.9594594594594595\n",
      "{'max_depth': 15, 'min_samples_leaf': 10, 'min_samples_split': 5, 'n_estimators': 400}\n",
      "F1 score is------------------------------------ 0.9594594594594595\n",
      "{'max_depth': 15, 'min_samples_leaf': 10, 'min_samples_split': 5, 'n_estimators': 800}\n",
      "F1 score is------------------------------------ 0.9659863945578231\n",
      "{'max_depth': 15, 'min_samples_leaf': 20, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "F1 score is------------------------------------ 0.9161290322580645\n",
      "{'max_depth': 15, 'min_samples_leaf': 20, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "F1 score is------------------------------------ 0.9594594594594595\n",
      "{'max_depth': 15, 'min_samples_leaf': 20, 'min_samples_split': 2, 'n_estimators': 400}\n",
      "F1 score is------------------------------------ 0.9403973509933775\n",
      "{'max_depth': 15, 'min_samples_leaf': 20, 'min_samples_split': 2, 'n_estimators': 800}\n",
      "F1 score is------------------------------------ 0.9281045751633987\n",
      "{'max_depth': 15, 'min_samples_leaf': 20, 'min_samples_split': 3, 'n_estimators': 100}\n",
      "F1 score is------------------------------------ 0.9161290322580645\n",
      "{'max_depth': 15, 'min_samples_leaf': 20, 'min_samples_split': 3, 'n_estimators': 200}\n",
      "F1 score is------------------------------------ 0.9594594594594595\n",
      "{'max_depth': 15, 'min_samples_leaf': 20, 'min_samples_split': 3, 'n_estimators': 400}\n",
      "F1 score is------------------------------------ 0.9403973509933775\n",
      "{'max_depth': 15, 'min_samples_leaf': 20, 'min_samples_split': 3, 'n_estimators': 800}\n",
      "F1 score is------------------------------------ 0.9281045751633987\n",
      "{'max_depth': 15, 'min_samples_leaf': 20, 'min_samples_split': 4, 'n_estimators': 100}\n",
      "F1 score is------------------------------------ 0.9161290322580645\n",
      "{'max_depth': 15, 'min_samples_leaf': 20, 'min_samples_split': 4, 'n_estimators': 200}\n",
      "F1 score is------------------------------------ 0.9594594594594595\n",
      "{'max_depth': 15, 'min_samples_leaf': 20, 'min_samples_split': 4, 'n_estimators': 400}\n",
      "F1 score is------------------------------------ 0.9403973509933775\n",
      "{'max_depth': 15, 'min_samples_leaf': 20, 'min_samples_split': 4, 'n_estimators': 800}\n",
      "F1 score is------------------------------------ 0.9281045751633987\n",
      "{'max_depth': 15, 'min_samples_leaf': 20, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "F1 score is------------------------------------ 0.9161290322580645\n",
      "{'max_depth': 15, 'min_samples_leaf': 20, 'min_samples_split': 5, 'n_estimators': 200}\n",
      "F1 score is------------------------------------ 0.9594594594594595\n",
      "{'max_depth': 15, 'min_samples_leaf': 20, 'min_samples_split': 5, 'n_estimators': 400}\n",
      "F1 score is------------------------------------ 0.9403973509933775\n",
      "{'max_depth': 15, 'min_samples_leaf': 20, 'min_samples_split': 5, 'n_estimators': 800}\n",
      "F1 score is------------------------------------ 0.9281045751633987\n",
      "{'max_depth': 25, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "F1 score is------------------------------------ 0.9640287769784173\n",
      "{'max_depth': 25, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "F1 score is------------------------------------ 0.9565217391304348\n",
      "{'max_depth': 25, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 400}\n",
      "F1 score is------------------------------------ 0.9565217391304348\n",
      "{'max_depth': 25, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 800}\n",
      "F1 score is------------------------------------ 0.9565217391304348\n",
      "{'max_depth': 25, 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 100}\n",
      "F1 score is------------------------------------ 0.9640287769784173\n",
      "{'max_depth': 25, 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 200}\n",
      "F1 score is------------------------------------ 0.9640287769784173\n",
      "{'max_depth': 25, 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 400}\n",
      "F1 score is------------------------------------ 0.9571428571428572\n",
      "{'max_depth': 25, 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 800}\n",
      "F1 score is------------------------------------ 0.949640287769784\n",
      "{'max_depth': 25, 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 100}\n",
      "F1 score is------------------------------------ 0.9645390070921985\n",
      "{'max_depth': 25, 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 200}\n",
      "F1 score is------------------------------------ 0.9640287769784173\n",
      "{'max_depth': 25, 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 400}\n",
      "F1 score is------------------------------------ 0.9571428571428572\n",
      "{'max_depth': 25, 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 800}\n",
      "F1 score is------------------------------------ 0.9640287769784173\n",
      "{'max_depth': 25, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 100}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score is------------------------------------ 0.9640287769784173\n",
      "{'max_depth': 25, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 200}\n",
      "F1 score is------------------------------------ 0.9489051094890512\n",
      "{'max_depth': 25, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 400}\n",
      "F1 score is------------------------------------ 0.9640287769784173\n",
      "{'max_depth': 25, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 800}\n",
      "F1 score is------------------------------------ 0.9640287769784173\n",
      "{'max_depth': 25, 'min_samples_leaf': 10, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "F1 score is------------------------------------ 0.9583333333333334\n",
      "{'max_depth': 25, 'min_samples_leaf': 10, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "F1 score is------------------------------------ 0.9659863945578231\n",
      "{'max_depth': 25, 'min_samples_leaf': 10, 'min_samples_split': 2, 'n_estimators': 400}\n",
      "F1 score is------------------------------------ 0.9659863945578231\n",
      "{'max_depth': 25, 'min_samples_leaf': 10, 'min_samples_split': 2, 'n_estimators': 800}\n",
      "F1 score is------------------------------------ 0.9659863945578231\n",
      "{'max_depth': 25, 'min_samples_leaf': 10, 'min_samples_split': 3, 'n_estimators': 100}\n",
      "F1 score is------------------------------------ 0.9583333333333334\n",
      "{'max_depth': 25, 'min_samples_leaf': 10, 'min_samples_split': 3, 'n_estimators': 200}\n",
      "F1 score is------------------------------------ 0.9659863945578231\n",
      "{'max_depth': 25, 'min_samples_leaf': 10, 'min_samples_split': 3, 'n_estimators': 400}\n",
      "F1 score is------------------------------------ 0.9659863945578231\n",
      "{'max_depth': 25, 'min_samples_leaf': 10, 'min_samples_split': 3, 'n_estimators': 800}\n",
      "F1 score is------------------------------------ 0.9659863945578231\n",
      "{'max_depth': 25, 'min_samples_leaf': 10, 'min_samples_split': 4, 'n_estimators': 100}\n",
      "F1 score is------------------------------------ 0.9583333333333334\n",
      "{'max_depth': 25, 'min_samples_leaf': 10, 'min_samples_split': 4, 'n_estimators': 200}\n",
      "F1 score is------------------------------------ 0.9659863945578231\n",
      "{'max_depth': 25, 'min_samples_leaf': 10, 'min_samples_split': 4, 'n_estimators': 400}\n",
      "F1 score is------------------------------------ 0.9659863945578231\n",
      "{'max_depth': 25, 'min_samples_leaf': 10, 'min_samples_split': 4, 'n_estimators': 800}\n",
      "F1 score is------------------------------------ 0.9659863945578231\n",
      "{'max_depth': 25, 'min_samples_leaf': 10, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "F1 score is------------------------------------ 0.9583333333333334\n",
      "{'max_depth': 25, 'min_samples_leaf': 10, 'min_samples_split': 5, 'n_estimators': 200}\n",
      "F1 score is------------------------------------ 0.9659863945578231\n",
      "{'max_depth': 25, 'min_samples_leaf': 10, 'min_samples_split': 5, 'n_estimators': 400}\n",
      "F1 score is------------------------------------ 0.9659863945578231\n",
      "{'max_depth': 25, 'min_samples_leaf': 10, 'min_samples_split': 5, 'n_estimators': 800}\n",
      "F1 score is------------------------------------ 0.9659863945578231\n",
      "{'max_depth': 25, 'min_samples_leaf': 20, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "F1 score is------------------------------------ 0.9161290322580645\n",
      "{'max_depth': 25, 'min_samples_leaf': 20, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "F1 score is------------------------------------ 0.953020134228188\n",
      "{'max_depth': 25, 'min_samples_leaf': 20, 'min_samples_split': 2, 'n_estimators': 400}\n",
      "F1 score is------------------------------------ 0.9403973509933775\n",
      "{'max_depth': 25, 'min_samples_leaf': 20, 'min_samples_split': 2, 'n_estimators': 800}\n",
      "F1 score is------------------------------------ 0.9281045751633987\n",
      "{'max_depth': 25, 'min_samples_leaf': 20, 'min_samples_split': 3, 'n_estimators': 100}\n",
      "F1 score is------------------------------------ 0.9161290322580645\n",
      "{'max_depth': 25, 'min_samples_leaf': 20, 'min_samples_split': 3, 'n_estimators': 200}\n",
      "F1 score is------------------------------------ 0.953020134228188\n",
      "{'max_depth': 25, 'min_samples_leaf': 20, 'min_samples_split': 3, 'n_estimators': 400}\n",
      "F1 score is------------------------------------ 0.9403973509933775\n",
      "{'max_depth': 25, 'min_samples_leaf': 20, 'min_samples_split': 3, 'n_estimators': 800}\n",
      "F1 score is------------------------------------ 0.9281045751633987\n",
      "{'max_depth': 25, 'min_samples_leaf': 20, 'min_samples_split': 4, 'n_estimators': 100}\n",
      "F1 score is------------------------------------ 0.9161290322580645\n",
      "{'max_depth': 25, 'min_samples_leaf': 20, 'min_samples_split': 4, 'n_estimators': 200}\n",
      "F1 score is------------------------------------ 0.953020134228188\n",
      "{'max_depth': 25, 'min_samples_leaf': 20, 'min_samples_split': 4, 'n_estimators': 400}\n",
      "F1 score is------------------------------------ 0.9403973509933775\n",
      "{'max_depth': 25, 'min_samples_leaf': 20, 'min_samples_split': 4, 'n_estimators': 800}\n",
      "F1 score is------------------------------------ 0.9281045751633987\n",
      "{'max_depth': 25, 'min_samples_leaf': 20, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "F1 score is------------------------------------ 0.9161290322580645\n",
      "{'max_depth': 25, 'min_samples_leaf': 20, 'min_samples_split': 5, 'n_estimators': 200}\n",
      "F1 score is------------------------------------ 0.953020134228188\n",
      "{'max_depth': 25, 'min_samples_leaf': 20, 'min_samples_split': 5, 'n_estimators': 400}\n",
      "F1 score is------------------------------------ 0.9403973509933775\n",
      "{'max_depth': 25, 'min_samples_leaf': 20, 'min_samples_split': 5, 'n_estimators': 800}\n",
      "F1 score is------------------------------------ 0.9281045751633987\n"
     ]
    }
   ],
   "source": [
    "# optimize model for tf-idf feature input\n",
    "model_parameters = pd.DataFrame(columns = ['f1','Parameters'])\n",
    "max_f1 = 0\n",
    "max_parameters = []\n",
    "for p in grid:\n",
    "    test = pd.DataFrame()\n",
    "    print(p)\n",
    "    train_model =RandomForestClassifier(\n",
    "                                        n_estimators = p['n_estimators'],\n",
    "                                        max_depth = p['max_depth'],\n",
    "                                        min_samples_split = p['min_samples_split'],\n",
    "                                        min_samples_leaf = p['min_samples_leaf'],\n",
    "#                                         min_weight_fraction_leaf = p['min_weight_fraction_leaf'],       \n",
    "                                        random_state = 0,\n",
    "                                        class_weight = 'balanced',\n",
    "                                        )\n",
    "    train_model.fit(train_X_tfidf,train_y_tfidf)\n",
    "    val_tfidf_forecast = train_model.predict(val_X_tfidf)\n",
    "    f1 = f1_score(val_y_tfidf, val_tfidf_forecast)\n",
    "    print('F1 score is------------------------------------',f1)\n",
    "    if f1 > max_f1:\n",
    "        max_f1 = f1\n",
    "        max_parameters = p\n",
    "    model_parameters = model_parameters.append({'f1':f1,'Parameters':p},ignore_index=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max f1_score for tf-idf feature is 0.9714285714285714\n",
      "The best paremeters are {'max_depth': 15, 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 800}\n"
     ]
    }
   ],
   "source": [
    "print(\"max f1_score for tf-idf feature is\", max_f1)\n",
    "print('The best paremeters are',max_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>min_samples_split</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>800</td>\n",
       "      <td>0.971429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>0.971429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>800</td>\n",
       "      <td>0.965986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>800</td>\n",
       "      <td>0.965986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>800</td>\n",
       "      <td>0.965986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>800</td>\n",
       "      <td>0.965986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>25</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>0.965986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>25</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>400</td>\n",
       "      <td>0.965986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>25</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>800</td>\n",
       "      <td>0.965986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>25</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>0.965986</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     max_depth  min_samples_leaf  min_samples_split  n_estimators        f1\n",
       "55          15                 1                  3           800  0.971429\n",
       "60          15                 1                  5           100  0.971429\n",
       "67          15                10                  2           800  0.965986\n",
       "71          15                10                  3           800  0.965986\n",
       "75          15                10                  4           800  0.965986\n",
       "79          15                10                  5           800  0.965986\n",
       "113         25                10                  2           200  0.965986\n",
       "114         25                10                  2           400  0.965986\n",
       "115         25                10                  2           800  0.965986\n",
       "117         25                10                  3           200  0.965986"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_model_parameters = model_parameters['Parameters'].apply(pd.Series)\n",
    "tfidf_model_parameters['f1'] = model_parameters['f1']\n",
    "tfidf_model_parameters.nlargest(10, 'f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x576 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axs = plt.subplots(3)\n",
    "fig.set_figheight(8)\n",
    "fig.set_figwidth(4)\n",
    "\n",
    "p1 = axs[0].scatter(tfidf_model_parameters['min_samples_split'], tfidf_model_parameters['f1'], c=tfidf_model_parameters['f1'],cmap = 'Blues')\n",
    "axs[0].set_title('min_samples_split vs f1 socre')\n",
    "axs[0].set_ylim([0.85, 1])\n",
    "axs[1].scatter(tfidf_model_parameters['n_estimators'], tfidf_model_parameters['f1'],c=tfidf_model_parameters['f1'],cmap = 'Blues')\n",
    "axs[1].set_title('n_estimators vs f1 socre')\n",
    "axs[1].set_ylim([0.85, 1])\n",
    "axs[2].scatter(tfidf_model_parameters['min_samples_leaf'], tfidf_model_parameters['f1'],c=tfidf_model_parameters['f1'],cmap = 'Blues')\n",
    "axs[2].set_title('min_samples_leaf vs f1 socre')\n",
    "axs[2].set_ylim([0.85, 1])\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfopt = RandomForestClassifier(random_state = 0,\n",
    "                               n_estimators = 800,\n",
    "                               max_depth= 15, \n",
    "                               min_samples_leaf=1, \n",
    "                               min_samples_split = 3,\n",
    "                              class_weight = 'balanced') \n",
    "rfopt.fit(train_X_tfidf, train_y_tfidf) \n",
    "predic_tfidf_opt = rfopt.predict(val_X_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_tfdif_opt_val = accuracy_score(predic_tfidf_opt,val_y_tfidf)\n",
    "f1_tfdif_opt_val = f1_score(predic_tfidf_opt,val_y_tfidf)\n",
    "cm_tfdif_opt_val = confusion_matrix(predic_tfidf_opt,val_y_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mesure for tf-idf feature with optimized model on validation data:\n",
      "accuracy is        : 0.9922928709055877\n",
      "f1 is              : 0.9714285714285714\n",
      "confusion matrix is:\n",
      " [[447   4]\n",
      " [  0  68]]\n"
     ]
    }
   ],
   "source": [
    "print('mesure for tf-idf feature with optimized model on validation data:')\n",
    "print('accuracy is        :',accuracy_tfdif_opt_val)\n",
    "print('f1 is              :',f1_tfdif_opt_val)\n",
    "print('confusion matrix is:\\n',cm_tfdif_opt_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "predic_tfidf_test = rfopt.predict(test_X_tfidf)\n",
    "accuracy_tfdif_opt_test = accuracy_score(predic_tfidf_test,test_y_tfidf)\n",
    "f1_tfdif_opt_test = f1_score(predic_tfidf_test,test_y_tfidf)\n",
    "cm_tfdif_opt_test = confusion_matrix(predic_tfidf_test,test_y_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mesure for tf-idf feature with optimized model on test data:\n",
      "accuracy is        : 0.9826923076923076\n",
      "f1 is              : 0.9411764705882354\n",
      "confusion matrix is:\n",
      " [[439   8]\n",
      " [  1  72]]\n"
     ]
    }
   ],
   "source": [
    "print('mesure for tf-idf feature with optimized model on test data:')\n",
    "print('accuracy is        :',accuracy_tfdif_opt_test)\n",
    "print('f1 is              :',f1_tfdif_opt_test)\n",
    "print('confusion matrix is:\\n',cm_tfdif_opt_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### the model with BOW feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Possible Models 144\n"
     ]
    }
   ],
   "source": [
    "params_grid = {\n",
    "                'n_estimators':[100,200,400,800],\n",
    "               'max_depth':[5,15,25],\n",
    "                'min_samples_split' :[2,3,4,5],\n",
    "               'min_samples_leaf': [1,10,20],\n",
    "#                'min_weight_fraction_leaf': [0.0,0.25,0.5] #best performance got from 0.0\n",
    "              }\n",
    "grid = ParameterGrid(params_grid)\n",
    "cnt = 0\n",
    "for p in grid:\n",
    "    cnt = cnt+1\n",
    "\n",
    "print('Total Possible Models',cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "F1 score is------------------------------------ 0.9130434782608695\n",
      "{'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "F1 score is------------------------------------ 0.9208633093525178\n",
      "{'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 400}\n",
      "F1 score is------------------------------------ 0.9051094890510949\n",
      "{'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 800}\n",
      "F1 score is------------------------------------ 0.9197080291970802\n",
      "{'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 100}\n",
      "F1 score is------------------------------------ 0.9064748201438849\n",
      "{'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 200}\n",
      "F1 score is------------------------------------ 0.9208633093525178\n",
      "{'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 400}\n",
      "F1 score is------------------------------------ 0.9051094890510949\n",
      "{'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 800}\n",
      "F1 score is------------------------------------ 0.9197080291970802\n",
      "{'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 100}\n",
      "F1 score is------------------------------------ 0.9064748201438849\n",
      "{'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 200}\n",
      "F1 score is------------------------------------ 0.9208633093525178\n",
      "{'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 400}\n",
      "F1 score is------------------------------------ 0.9051094890510949\n",
      "{'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 800}\n",
      "F1 score is------------------------------------ 0.927536231884058\n",
      "{'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "F1 score is------------------------------------ 0.9064748201438849\n",
      "{'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 200}\n",
      "F1 score is------------------------------------ 0.9208633093525178\n",
      "{'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 400}\n",
      "F1 score is------------------------------------ 0.9051094890510949\n",
      "{'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 800}\n",
      "F1 score is------------------------------------ 0.927536231884058\n",
      "{'max_depth': 5, 'min_samples_leaf': 10, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "F1 score is------------------------------------ 0.9295774647887323\n",
      "{'max_depth': 5, 'min_samples_leaf': 10, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "F1 score is------------------------------------ 0.9295774647887323\n",
      "{'max_depth': 5, 'min_samples_leaf': 10, 'min_samples_split': 2, 'n_estimators': 400}\n",
      "F1 score is------------------------------------ 0.9208633093525178\n",
      "{'max_depth': 5, 'min_samples_leaf': 10, 'min_samples_split': 2, 'n_estimators': 800}\n",
      "F1 score is------------------------------------ 0.9352517985611511\n",
      "{'max_depth': 5, 'min_samples_leaf': 10, 'min_samples_split': 3, 'n_estimators': 100}\n",
      "F1 score is------------------------------------ 0.9295774647887323\n",
      "{'max_depth': 5, 'min_samples_leaf': 10, 'min_samples_split': 3, 'n_estimators': 200}\n",
      "F1 score is------------------------------------ 0.9295774647887323\n",
      "{'max_depth': 5, 'min_samples_leaf': 10, 'min_samples_split': 3, 'n_estimators': 400}\n",
      "F1 score is------------------------------------ 0.9208633093525178\n",
      "{'max_depth': 5, 'min_samples_leaf': 10, 'min_samples_split': 3, 'n_estimators': 800}\n",
      "F1 score is------------------------------------ 0.9352517985611511\n",
      "{'max_depth': 5, 'min_samples_leaf': 10, 'min_samples_split': 4, 'n_estimators': 100}\n",
      "F1 score is------------------------------------ 0.9295774647887323\n",
      "{'max_depth': 5, 'min_samples_leaf': 10, 'min_samples_split': 4, 'n_estimators': 200}\n",
      "F1 score is------------------------------------ 0.9295774647887323\n",
      "{'max_depth': 5, 'min_samples_leaf': 10, 'min_samples_split': 4, 'n_estimators': 400}\n",
      "F1 score is------------------------------------ 0.9208633093525178\n",
      "{'max_depth': 5, 'min_samples_leaf': 10, 'min_samples_split': 4, 'n_estimators': 800}\n",
      "F1 score is------------------------------------ 0.9352517985611511\n",
      "{'max_depth': 5, 'min_samples_leaf': 10, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "F1 score is------------------------------------ 0.9295774647887323\n",
      "{'max_depth': 5, 'min_samples_leaf': 10, 'min_samples_split': 5, 'n_estimators': 200}\n",
      "F1 score is------------------------------------ 0.9295774647887323\n",
      "{'max_depth': 5, 'min_samples_leaf': 10, 'min_samples_split': 5, 'n_estimators': 400}\n",
      "F1 score is------------------------------------ 0.9208633093525178\n",
      "{'max_depth': 5, 'min_samples_leaf': 10, 'min_samples_split': 5, 'n_estimators': 800}\n",
      "F1 score is------------------------------------ 0.9352517985611511\n",
      "{'max_depth': 5, 'min_samples_leaf': 20, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "F1 score is------------------------------------ 0.9452054794520548\n",
      "{'max_depth': 5, 'min_samples_leaf': 20, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "F1 score is------------------------------------ 0.9315068493150684\n",
      "{'max_depth': 5, 'min_samples_leaf': 20, 'min_samples_split': 2, 'n_estimators': 400}\n",
      "F1 score is------------------------------------ 0.9154929577464788\n",
      "{'max_depth': 5, 'min_samples_leaf': 20, 'min_samples_split': 2, 'n_estimators': 800}\n",
      "F1 score is------------------------------------ 0.9361702127659574\n",
      "{'max_depth': 5, 'min_samples_leaf': 20, 'min_samples_split': 3, 'n_estimators': 100}\n",
      "F1 score is------------------------------------ 0.9452054794520548\n",
      "{'max_depth': 5, 'min_samples_leaf': 20, 'min_samples_split': 3, 'n_estimators': 200}\n",
      "F1 score is------------------------------------ 0.9315068493150684\n",
      "{'max_depth': 5, 'min_samples_leaf': 20, 'min_samples_split': 3, 'n_estimators': 400}\n",
      "F1 score is------------------------------------ 0.9154929577464788\n",
      "{'max_depth': 5, 'min_samples_leaf': 20, 'min_samples_split': 3, 'n_estimators': 800}\n",
      "F1 score is------------------------------------ 0.9361702127659574\n",
      "{'max_depth': 5, 'min_samples_leaf': 20, 'min_samples_split': 4, 'n_estimators': 100}\n",
      "F1 score is------------------------------------ 0.9452054794520548\n",
      "{'max_depth': 5, 'min_samples_leaf': 20, 'min_samples_split': 4, 'n_estimators': 200}\n",
      "F1 score is------------------------------------ 0.9315068493150684\n",
      "{'max_depth': 5, 'min_samples_leaf': 20, 'min_samples_split': 4, 'n_estimators': 400}\n",
      "F1 score is------------------------------------ 0.9154929577464788\n",
      "{'max_depth': 5, 'min_samples_leaf': 20, 'min_samples_split': 4, 'n_estimators': 800}\n",
      "F1 score is------------------------------------ 0.9361702127659574\n",
      "{'max_depth': 5, 'min_samples_leaf': 20, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "F1 score is------------------------------------ 0.9452054794520548\n",
      "{'max_depth': 5, 'min_samples_leaf': 20, 'min_samples_split': 5, 'n_estimators': 200}\n",
      "F1 score is------------------------------------ 0.9315068493150684\n",
      "{'max_depth': 5, 'min_samples_leaf': 20, 'min_samples_split': 5, 'n_estimators': 400}\n",
      "F1 score is------------------------------------ 0.9154929577464788\n",
      "{'max_depth': 5, 'min_samples_leaf': 20, 'min_samples_split': 5, 'n_estimators': 800}\n",
      "F1 score is------------------------------------ 0.9361702127659574\n",
      "{'max_depth': 15, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "F1 score is------------------------------------ 0.9645390070921985\n",
      "{'max_depth': 15, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "F1 score is------------------------------------ 0.971830985915493\n",
      "{'max_depth': 15, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 400}\n",
      "F1 score is------------------------------------ 0.9859154929577464\n",
      "{'max_depth': 15, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 800}\n",
      "F1 score is------------------------------------ 0.9859154929577464\n",
      "{'max_depth': 15, 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 100}\n",
      "F1 score is------------------------------------ 0.9640287769784173\n",
      "{'max_depth': 15, 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 200}\n",
      "F1 score is------------------------------------ 0.9787234042553191\n",
      "{'max_depth': 15, 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 400}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score is------------------------------------ 0.9859154929577464\n",
      "{'max_depth': 15, 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 800}\n",
      "F1 score is------------------------------------ 0.9859154929577464\n",
      "{'max_depth': 15, 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 100}\n",
      "F1 score is------------------------------------ 0.9714285714285714\n",
      "{'max_depth': 15, 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 200}\n",
      "F1 score is------------------------------------ 0.9787234042553191\n",
      "{'max_depth': 15, 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 400}\n",
      "F1 score is------------------------------------ 0.9859154929577464\n",
      "{'max_depth': 15, 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 800}\n",
      "F1 score is------------------------------------ 0.9859154929577464\n",
      "{'max_depth': 15, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "F1 score is------------------------------------ 0.9640287769784173\n",
      "{'max_depth': 15, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 200}\n",
      "F1 score is------------------------------------ 0.9787234042553191\n",
      "{'max_depth': 15, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 400}\n",
      "F1 score is------------------------------------ 0.9714285714285714\n",
      "{'max_depth': 15, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 800}\n",
      "F1 score is------------------------------------ 0.9859154929577464\n",
      "{'max_depth': 15, 'min_samples_leaf': 10, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "F1 score is------------------------------------ 0.9333333333333333\n",
      "{'max_depth': 15, 'min_samples_leaf': 10, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "F1 score is------------------------------------ 0.9210526315789473\n",
      "{'max_depth': 15, 'min_samples_leaf': 10, 'min_samples_split': 2, 'n_estimators': 400}\n",
      "F1 score is------------------------------------ 0.9395973154362416\n",
      "{'max_depth': 15, 'min_samples_leaf': 10, 'min_samples_split': 2, 'n_estimators': 800}\n",
      "F1 score is------------------------------------ 0.9403973509933775\n",
      "{'max_depth': 15, 'min_samples_leaf': 10, 'min_samples_split': 3, 'n_estimators': 100}\n",
      "F1 score is------------------------------------ 0.9333333333333333\n",
      "{'max_depth': 15, 'min_samples_leaf': 10, 'min_samples_split': 3, 'n_estimators': 200}\n",
      "F1 score is------------------------------------ 0.9210526315789473\n",
      "{'max_depth': 15, 'min_samples_leaf': 10, 'min_samples_split': 3, 'n_estimators': 400}\n",
      "F1 score is------------------------------------ 0.9395973154362416\n",
      "{'max_depth': 15, 'min_samples_leaf': 10, 'min_samples_split': 3, 'n_estimators': 800}\n",
      "F1 score is------------------------------------ 0.9403973509933775\n",
      "{'max_depth': 15, 'min_samples_leaf': 10, 'min_samples_split': 4, 'n_estimators': 100}\n",
      "F1 score is------------------------------------ 0.9333333333333333\n",
      "{'max_depth': 15, 'min_samples_leaf': 10, 'min_samples_split': 4, 'n_estimators': 200}\n",
      "F1 score is------------------------------------ 0.9210526315789473\n",
      "{'max_depth': 15, 'min_samples_leaf': 10, 'min_samples_split': 4, 'n_estimators': 400}\n",
      "F1 score is------------------------------------ 0.9395973154362416\n",
      "{'max_depth': 15, 'min_samples_leaf': 10, 'min_samples_split': 4, 'n_estimators': 800}\n",
      "F1 score is------------------------------------ 0.9403973509933775\n",
      "{'max_depth': 15, 'min_samples_leaf': 10, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "F1 score is------------------------------------ 0.9333333333333333\n",
      "{'max_depth': 15, 'min_samples_leaf': 10, 'min_samples_split': 5, 'n_estimators': 200}\n",
      "F1 score is------------------------------------ 0.9210526315789473\n",
      "{'max_depth': 15, 'min_samples_leaf': 10, 'min_samples_split': 5, 'n_estimators': 400}\n",
      "F1 score is------------------------------------ 0.9395973154362416\n",
      "{'max_depth': 15, 'min_samples_leaf': 10, 'min_samples_split': 5, 'n_estimators': 800}\n",
      "F1 score is------------------------------------ 0.9403973509933775\n",
      "{'max_depth': 15, 'min_samples_leaf': 20, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "F1 score is------------------------------------ 0.8860759493670887\n",
      "{'max_depth': 15, 'min_samples_leaf': 20, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "F1 score is------------------------------------ 0.875\n",
      "{'max_depth': 15, 'min_samples_leaf': 20, 'min_samples_split': 2, 'n_estimators': 400}\n",
      "F1 score is------------------------------------ 0.9044585987261147\n",
      "{'max_depth': 15, 'min_samples_leaf': 20, 'min_samples_split': 2, 'n_estimators': 800}\n",
      "F1 score is------------------------------------ 0.9220779220779222\n",
      "{'max_depth': 15, 'min_samples_leaf': 20, 'min_samples_split': 3, 'n_estimators': 100}\n",
      "F1 score is------------------------------------ 0.8860759493670887\n",
      "{'max_depth': 15, 'min_samples_leaf': 20, 'min_samples_split': 3, 'n_estimators': 200}\n",
      "F1 score is------------------------------------ 0.875\n",
      "{'max_depth': 15, 'min_samples_leaf': 20, 'min_samples_split': 3, 'n_estimators': 400}\n",
      "F1 score is------------------------------------ 0.9044585987261147\n",
      "{'max_depth': 15, 'min_samples_leaf': 20, 'min_samples_split': 3, 'n_estimators': 800}\n",
      "F1 score is------------------------------------ 0.9220779220779222\n",
      "{'max_depth': 15, 'min_samples_leaf': 20, 'min_samples_split': 4, 'n_estimators': 100}\n",
      "F1 score is------------------------------------ 0.8860759493670887\n",
      "{'max_depth': 15, 'min_samples_leaf': 20, 'min_samples_split': 4, 'n_estimators': 200}\n",
      "F1 score is------------------------------------ 0.875\n",
      "{'max_depth': 15, 'min_samples_leaf': 20, 'min_samples_split': 4, 'n_estimators': 400}\n",
      "F1 score is------------------------------------ 0.9044585987261147\n",
      "{'max_depth': 15, 'min_samples_leaf': 20, 'min_samples_split': 4, 'n_estimators': 800}\n",
      "F1 score is------------------------------------ 0.9220779220779222\n",
      "{'max_depth': 15, 'min_samples_leaf': 20, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "F1 score is------------------------------------ 0.8860759493670887\n",
      "{'max_depth': 15, 'min_samples_leaf': 20, 'min_samples_split': 5, 'n_estimators': 200}\n",
      "F1 score is------------------------------------ 0.875\n",
      "{'max_depth': 15, 'min_samples_leaf': 20, 'min_samples_split': 5, 'n_estimators': 400}\n",
      "F1 score is------------------------------------ 0.9044585987261147\n",
      "{'max_depth': 15, 'min_samples_leaf': 20, 'min_samples_split': 5, 'n_estimators': 800}\n",
      "F1 score is------------------------------------ 0.9220779220779222\n",
      "{'max_depth': 25, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "F1 score is------------------------------------ 0.9571428571428572\n",
      "{'max_depth': 25, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "F1 score is------------------------------------ 0.9645390070921985\n",
      "{'max_depth': 25, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 400}\n",
      "F1 score is------------------------------------ 0.9787234042553191\n",
      "{'max_depth': 25, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 800}\n",
      "F1 score is------------------------------------ 0.9859154929577464\n",
      "{'max_depth': 25, 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 100}\n",
      "F1 score is------------------------------------ 0.9640287769784173\n",
      "{'max_depth': 25, 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 200}\n",
      "F1 score is------------------------------------ 0.9787234042553191\n",
      "{'max_depth': 25, 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 400}\n",
      "F1 score is------------------------------------ 0.9787234042553191\n",
      "{'max_depth': 25, 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 800}\n",
      "F1 score is------------------------------------ 0.9859154929577464\n",
      "{'max_depth': 25, 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 100}\n",
      "F1 score is------------------------------------ 0.9645390070921985\n",
      "{'max_depth': 25, 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 200}\n",
      "F1 score is------------------------------------ 0.971830985915493\n",
      "{'max_depth': 25, 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 400}\n",
      "F1 score is------------------------------------ 0.9787234042553191\n",
      "{'max_depth': 25, 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 800}\n",
      "F1 score is------------------------------------ 0.9859154929577464\n",
      "{'max_depth': 25, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 100}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score is------------------------------------ 0.9571428571428572\n",
      "{'max_depth': 25, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 200}\n",
      "F1 score is------------------------------------ 0.971830985915493\n",
      "{'max_depth': 25, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 400}\n",
      "F1 score is------------------------------------ 0.9787234042553191\n",
      "{'max_depth': 25, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 800}\n",
      "F1 score is------------------------------------ 0.9859154929577464\n",
      "{'max_depth': 25, 'min_samples_leaf': 10, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "F1 score is------------------------------------ 0.9271523178807947\n",
      "{'max_depth': 25, 'min_samples_leaf': 10, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "F1 score is------------------------------------ 0.9210526315789473\n",
      "{'max_depth': 25, 'min_samples_leaf': 10, 'min_samples_split': 2, 'n_estimators': 400}\n",
      "F1 score is------------------------------------ 0.9395973154362416\n",
      "{'max_depth': 25, 'min_samples_leaf': 10, 'min_samples_split': 2, 'n_estimators': 800}\n",
      "F1 score is------------------------------------ 0.9466666666666667\n",
      "{'max_depth': 25, 'min_samples_leaf': 10, 'min_samples_split': 3, 'n_estimators': 100}\n",
      "F1 score is------------------------------------ 0.9271523178807947\n",
      "{'max_depth': 25, 'min_samples_leaf': 10, 'min_samples_split': 3, 'n_estimators': 200}\n",
      "F1 score is------------------------------------ 0.9210526315789473\n",
      "{'max_depth': 25, 'min_samples_leaf': 10, 'min_samples_split': 3, 'n_estimators': 400}\n",
      "F1 score is------------------------------------ 0.9395973154362416\n",
      "{'max_depth': 25, 'min_samples_leaf': 10, 'min_samples_split': 3, 'n_estimators': 800}\n",
      "F1 score is------------------------------------ 0.9466666666666667\n",
      "{'max_depth': 25, 'min_samples_leaf': 10, 'min_samples_split': 4, 'n_estimators': 100}\n",
      "F1 score is------------------------------------ 0.9271523178807947\n",
      "{'max_depth': 25, 'min_samples_leaf': 10, 'min_samples_split': 4, 'n_estimators': 200}\n",
      "F1 score is------------------------------------ 0.9210526315789473\n",
      "{'max_depth': 25, 'min_samples_leaf': 10, 'min_samples_split': 4, 'n_estimators': 400}\n",
      "F1 score is------------------------------------ 0.9395973154362416\n",
      "{'max_depth': 25, 'min_samples_leaf': 10, 'min_samples_split': 4, 'n_estimators': 800}\n",
      "F1 score is------------------------------------ 0.9466666666666667\n",
      "{'max_depth': 25, 'min_samples_leaf': 10, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "F1 score is------------------------------------ 0.9271523178807947\n",
      "{'max_depth': 25, 'min_samples_leaf': 10, 'min_samples_split': 5, 'n_estimators': 200}\n",
      "F1 score is------------------------------------ 0.9210526315789473\n",
      "{'max_depth': 25, 'min_samples_leaf': 10, 'min_samples_split': 5, 'n_estimators': 400}\n",
      "F1 score is------------------------------------ 0.9395973154362416\n",
      "{'max_depth': 25, 'min_samples_leaf': 10, 'min_samples_split': 5, 'n_estimators': 800}\n",
      "F1 score is------------------------------------ 0.9466666666666667\n",
      "{'max_depth': 25, 'min_samples_leaf': 20, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "F1 score is------------------------------------ 0.8860759493670887\n",
      "{'max_depth': 25, 'min_samples_leaf': 20, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "F1 score is------------------------------------ 0.875\n",
      "{'max_depth': 25, 'min_samples_leaf': 20, 'min_samples_split': 2, 'n_estimators': 400}\n",
      "F1 score is------------------------------------ 0.9044585987261147\n",
      "{'max_depth': 25, 'min_samples_leaf': 20, 'min_samples_split': 2, 'n_estimators': 800}\n",
      "F1 score is------------------------------------ 0.9161290322580645\n",
      "{'max_depth': 25, 'min_samples_leaf': 20, 'min_samples_split': 3, 'n_estimators': 100}\n",
      "F1 score is------------------------------------ 0.8860759493670887\n",
      "{'max_depth': 25, 'min_samples_leaf': 20, 'min_samples_split': 3, 'n_estimators': 200}\n",
      "F1 score is------------------------------------ 0.875\n",
      "{'max_depth': 25, 'min_samples_leaf': 20, 'min_samples_split': 3, 'n_estimators': 400}\n",
      "F1 score is------------------------------------ 0.9044585987261147\n",
      "{'max_depth': 25, 'min_samples_leaf': 20, 'min_samples_split': 3, 'n_estimators': 800}\n",
      "F1 score is------------------------------------ 0.9161290322580645\n",
      "{'max_depth': 25, 'min_samples_leaf': 20, 'min_samples_split': 4, 'n_estimators': 100}\n",
      "F1 score is------------------------------------ 0.8860759493670887\n",
      "{'max_depth': 25, 'min_samples_leaf': 20, 'min_samples_split': 4, 'n_estimators': 200}\n",
      "F1 score is------------------------------------ 0.875\n",
      "{'max_depth': 25, 'min_samples_leaf': 20, 'min_samples_split': 4, 'n_estimators': 400}\n",
      "F1 score is------------------------------------ 0.9044585987261147\n",
      "{'max_depth': 25, 'min_samples_leaf': 20, 'min_samples_split': 4, 'n_estimators': 800}\n",
      "F1 score is------------------------------------ 0.9161290322580645\n",
      "{'max_depth': 25, 'min_samples_leaf': 20, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "F1 score is------------------------------------ 0.8860759493670887\n",
      "{'max_depth': 25, 'min_samples_leaf': 20, 'min_samples_split': 5, 'n_estimators': 200}\n",
      "F1 score is------------------------------------ 0.875\n",
      "{'max_depth': 25, 'min_samples_leaf': 20, 'min_samples_split': 5, 'n_estimators': 400}\n",
      "F1 score is------------------------------------ 0.9044585987261147\n",
      "{'max_depth': 25, 'min_samples_leaf': 20, 'min_samples_split': 5, 'n_estimators': 800}\n",
      "F1 score is------------------------------------ 0.9161290322580645\n"
     ]
    }
   ],
   "source": [
    "# optimize model for bag feature input\n",
    "model_parameters_bag = pd.DataFrame(columns = ['f1','Parameters'])\n",
    "max_f1_bag = 0\n",
    "max_parameters_bag = []\n",
    "for p in grid:\n",
    "    test = pd.DataFrame()\n",
    "    print(p)\n",
    "    train_model =RandomForestClassifier(\n",
    "                                        n_estimators = p['n_estimators'],\n",
    "                                        max_depth = p['max_depth'],\n",
    "                                        min_samples_split = p['min_samples_split'],\n",
    "                                        min_samples_leaf = p['min_samples_leaf'],         \n",
    "#                                         min_weight_fraction_leaf = p['min_weight_fraction_leaf'], #decrease perfomance       \n",
    "                                        random_state = 0,\n",
    "                                        class_weight = 'balanced'\n",
    "                                        )\n",
    "    train_model.fit(train_X_bag,train_y_bag)\n",
    "    val_bag_forecast = train_model.predict(val_X_bag)\n",
    "    f1 = f1_score(val_y_bag, val_bag_forecast)\n",
    "    print('F1 score is------------------------------------',f1)\n",
    "    if f1 > max_f1_bag:\n",
    "        max_f1_bag = f1\n",
    "        max_parameters_bag = p\n",
    "    model_parameters_bag = model_parameters_bag.append({'f1':f1,'Parameters':p},ignore_index=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max f1_score for bow feature is 0.9859154929577464\n",
      "The best paremeters are {'max_depth': 15, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 400}\n"
     ]
    }
   ],
   "source": [
    "print(\"max f1_score for bow feature is\", max_f1_bag)\n",
    "print('The best paremeters are',max_parameters_bag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>min_samples_split</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>400</td>\n",
       "      <td>0.985915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>800</td>\n",
       "      <td>0.985915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>400</td>\n",
       "      <td>0.985915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>800</td>\n",
       "      <td>0.985915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>400</td>\n",
       "      <td>0.985915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>800</td>\n",
       "      <td>0.985915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>800</td>\n",
       "      <td>0.985915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>800</td>\n",
       "      <td>0.985915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>800</td>\n",
       "      <td>0.985915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>800</td>\n",
       "      <td>0.985915</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     max_depth  min_samples_leaf  min_samples_split  n_estimators        f1\n",
       "50          15                 1                  2           400  0.985915\n",
       "51          15                 1                  2           800  0.985915\n",
       "54          15                 1                  3           400  0.985915\n",
       "55          15                 1                  3           800  0.985915\n",
       "58          15                 1                  4           400  0.985915\n",
       "59          15                 1                  4           800  0.985915\n",
       "63          15                 1                  5           800  0.985915\n",
       "99          25                 1                  2           800  0.985915\n",
       "103         25                 1                  3           800  0.985915\n",
       "107         25                 1                  4           800  0.985915"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_model_parameters = model_parameters_bag['Parameters'].apply(pd.Series)\n",
    "bow_model_parameters['f1'] = model_parameters_bag['f1']\n",
    "bow_model_parameters.nlargest(10, 'f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfopt_bag = RandomForestClassifier(random_state = 0,\n",
    "                               n_estimators = 800,\n",
    "                               max_depth= 15, \n",
    "                               min_samples_leaf=1, \n",
    "                               min_samples_split = 2,\n",
    "                              class_weight = 'balanced') \n",
    "rfopt_bag.fit(train_X_bag, train_y_bag) \n",
    "predic_bag_opt = rfopt_bag.predict(val_X_bag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_bag_opt_val = accuracy_score(predic_bag_opt,val_y_bag)\n",
    "f1_bag_opt_val = f1_score(predic_bag_opt,val_y_bag)\n",
    "cm_bag_opt_val = confusion_matrix(predic_bag_opt,val_y_bag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mesure for BOW feature with optimized model on validation data:\n",
      "accuracy is        : 0.9961464354527938\n",
      "f1 is              : 0.9859154929577464\n",
      "confusion matrix is:\n",
      " [[447   2]\n",
      " [  0  70]]\n"
     ]
    }
   ],
   "source": [
    "print('mesure for BOW feature with optimized model on validation data:')\n",
    "print('accuracy is        :',accuracy_bag_opt_val)\n",
    "print('f1 is              :',f1_bag_opt_val)\n",
    "print('confusion matrix is:\\n',cm_bag_opt_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "predic_bag_test = rfopt_bag.predict(test_X_bag)\n",
    "accuracy_bag_opt_test = accuracy_score(predic_bag_test,test_y_bag)\n",
    "f1_bag_opt_test = f1_score(predic_bag_test,test_y_bag)\n",
    "cm_bag_opt_test = confusion_matrix(predic_bag_test,test_y_bag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mesure for BOW feature with optimized model on test data:\n",
      "accuracy is        : 0.9846153846153847\n",
      "f1 is              : 0.9473684210526316\n",
      "confusion matrix is:\n",
      " [[440   8]\n",
      " [  0  72]]\n"
     ]
    }
   ],
   "source": [
    "print('mesure for BOW feature with optimized model on test data:')\n",
    "print('accuracy is        :',accuracy_bag_opt_test)\n",
    "print('f1 is              :',f1_bag_opt_test)\n",
    "print('confusion matrix is:\\n',cm_bag_opt_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
